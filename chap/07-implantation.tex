Dans ce chapitre, nous décrivons la mise en œuvre des analyses statiques
précédentes. Notons que, malgré qu'elles aient été décrites sur \langname, leur
implantation est faite sur la représentation intermédiaire \newspeak. Nous
commençons donc par décrire celle-ci. Ensuite, nous décrivons la phase de
compilation, de C à \newspeak, auquel on rajoute ensuite des étiquettes de
types. Celles-ci sont calculées par un algorithme d'inférence de types à la
Hindley-Milner, reposant sur l'unification et le partage de références. Toutes
ces étapes sont implantées dans le langage OCaml~\cite{DAOC}.

% TODO[S] pourquoi?

Le prototype décrit ici est disponible sur~\link{penjili} sous une license
libre, la \emph{GNU Lesser General Public License}.

\added{Nouvelle subsection}

\subsection*{Pourquoi \newspeak et pas \langname?}

% TODO[E] implantation safespeak

On peut se demander pourquoi analyser du code \newspeak et non \langname. Une
première raison est que de nombreux outils existent déjà autour du langage
\newspeak, notamment un compilateur depuis C et un analyseur statique par
interprétation abstraite. Le but de cette thèse est de permettre des analyses de
typage sur C, donc \newspeak est un bon support grâce à l'existence du
traducteur.

% TODO[E] voir avec la section modifiér du début sur les C--

Mais le modèle mémoire de \newspeak est très bas niveau. En effet il colle
finement à celui de C, où des constructions comme les unions empêchent la sûreté
du typage. Définir \langname a précisement pour but de définir un langage
inspiré de C mais sur lequel le typage peut être sûr.

Pour l'implantation sur \newspeak, on s'inspire donc des règles de typage sur
\langname, mais cette approche n'est sûre que pour les programmes qui peuvent
être fidèlement traduits.

% TODO[S] fidèlement
% TODO[S] pas clair: C -> Npk -> Spk?

Par exemple, un programme dans lequel on fait de l'arithmétique de pointeurs
entre champs de structures peut être traduit en \newspeak (et analysé par
interprétation abstraite), mais on ne peut rien en déduire du résultat d'une
analyse par typage.

On reviendra sur cette distinction entre les deux niveaux de sémantique dans la
conclusion de la partie~\ref{part:xp}, page~\pageref{page:ccl-npk-spk}.

\section{\newspeak et chaîne de compilation}
\label{sec:compil}

\newspeak est un langage intermédiaire conçu pour être un bon support d'analyses
statiques, contrairement à des langages conçus pour les programmeurs comme C. Sa
sémantique d'exécution (ainsi qu'une partie des étapes de compilation)
est décrite dans~\cite{newspeak}. Sa syntaxe est donnée dans la
figure~\ref{fig:stx-npk}.

\begin{figure}%{{{

\def\npkstyle#1{\mathrm{#1}}

\begin{align*}
\gramdef{Instruction}{s}
    {\npkstyle{Set} (lv, e, st)}{Affectation}
    {\npkstyle{Copy} (lv, lv, n)}{Copie}
    {\npkstyle{Guard} (e)}{Garde}
    {\npkstyle{Decl} (var, t, blk)}{Déclaration}
    {\npkstyle{Select} (blk, blk)}{Branchement}
    {\npkstyle{InfLoop} (blk)}{Boucle infinie}
    {\npkstyle{DoWith} (blk, x)}{Nommage de bloc}
    {\npkstyle{Goto} (x)}{Saut}
    {\npkstyle{Call} ([(e_i, t_i)], f, [(lv_i, t_i)])}
            {Appel de fonction}
    {END}
\\ \\
\gramdef{Bloc}{blk}
    {[i_i]}{Liste d'instructions}
    {END}
\\ \\
\gramdef{Valeur gauche}{lv}
    {\npkstyle{Local} (x)}{Locale}
    {\npkstyle{Global} (x)}{Globale}
    {\npkstyle{Deref} (e, n)}{Déréférencement}
    {\npkstyle{Shift} (lv, e)}{Décalage}
    {END}
\\ \\
\gramdef{Expression}{e}
    { \npkstyle{CInt} (n) }{Entier}
    { \npkstyle{CFloat} (d)}{Flottant}
    { \npkstyle{Nil} }{ Pointeur nul }
    { \npkstyle{Lval} (lv, t)}{Accès mémoire}
    { \npkstyle{AddrOf} (lv) }{Adresse de variable}
    { \npkstyle{AddrOfFun} (x, [t_i], [t_i])}{Adresse de fonction}
    { \npkstyle{UnOp} (unop, e) }{Opérateur unaire}
    { \npkstyle{BinOp} (binop, e_1, e_2) }{Opérateur binaire}
    {END}
\\ \\
\gramdef{Fonction}{f}
    { \npkstyle{FunId} (x)}{Appel par nom}
    { \npkstyle{FunDeref} (e)}{Appel par pointeur}
    {END}
\\ \\
\gramdef{Type}{t}
    { \npkstyle{Scalar} (st) }{Type scalaire}
    { \npkstyle{Array} (t, n)}{Tableau}
    { \npkstyle{Region} ([(n_i, t_i)], n')}{Structure/union}
    {END}
\\ \\
\gramdef{Type scalaire}{st}
    { \npkstyle{Int} (n) }{Entier}
    { \npkstyle{Float} (n) }{Flottant}
    { \npkstyle{Ptr} }{ Pointeur sur données}
    { \npkstyle{FunPtr}}{ Pointeur sur fonction}
    {END}
\end{align*}
\caption{Syntaxe simplifiée de \newspeak}
\label{fig:stx-npk}
\end{figure}%}}}

\begin{figure}
  \centering
  \input{fig/compil-pipeline.tex}
  \caption{Compilation depuis \newspeak}
\label{fig:compil-npk}
\end{figure}

La traduction depuis C est faite en trois étapes (figure~\ref{fig:compil-npk}):
prétraitement du code source par un outil externe, compilation séparée de C
prétraité vers des objets \newspeak{}, puis liaison de ces différentes unités de
compilation. Il est aussi possible de compiler directement du code Ada vers un
objet \newspeak{}.

La première étape consiste à prétraiter les fichiers C source avec le logiciel
\texttt{cpp}, comme pour une compilation normale. Cette étape interprète les
directives de prétraitement comme \texttt{\#include}, \texttt{\#ifdef}. À cet
étape, les commentaires sont aussi supprimés.

% TODO[S] cpp: dans la fig c'est gcc

Une fois cette passe effectuée, le résultat est un ensemble de fichiers C
prétraités; c'est-à-dire des unités de compilation.

Puisque la directive \texttt{\#include} est textuelle, ces fichiers sont très
grands et donnent lieu à beaucoup de duplication dans les passes suivantes.

% TODO[E] bcp de: fam

Sur cette représentation (du C prétraité), il est possible d'ajouter des
annotations de la forme \texttt{/*!npk [...] */} qui pourront être accessibles
dans l'arbre de syntaxe abstraite des passes suivantes.

% TODO[E] dire (plus tard) qu'on peut annoter et quelles annotations
% TODO[E] ann safespeak en C

À ce niveau, les fichiers sont passés à l'outil \ctonewspeak qui les
traduit vers \newspeak. Comme il sera décrit dans la section~\ref{sec:gnuc}, la
plupart des extensions GNU C sont acceptées en plus du C ANSI. Dans cette étape,
les types et les noms sont résolus, et le programme est annoté de manière à
rendre les prochaines étapes indépendantes du contexte. Par exemple, chaque
déclaration de variable est adjointe d'une description complète du type.

Lors de cette étape, le flot de contrôle est également simplifié. C en effet
propose de nombreuses constructions redondantes ou ambigües
(comme \texttt{i = i++}).

% TODO[S] ça serait mieux de donne un ex de flot complexe

Au contraire, \newspeak propose un nombre réduit de constructions. Rappelons que
le but de ce langage est de faciliter l'analyse statique: des constructions
orthogonales permettent donc d'éviter la duplication de règles sémantiques, ou
de code, lors de l'implantation d'un analyseur.

Par exemple, plutôt que de fournir une boucle \emph{while}, une boucle
\emph{do/while} et une boucle \emph{for}, \newspeak fournit une unique boucle
\phx\npkWhile. La sortie de boucle est compilée vers un \npkGoto{}\cite{goto},
qui est toujours un saut vers l'avant (similaire à un \enquote{\emph{break}}
généralisé). Par conséquence, notre implantation gère les sauts, alors que, dans
\langname, cette construction n'est pas possible (figure~\ref{fig:stx}, page
\pageref{fig:stx}).

% TODO[E] Par conséquence... : et donc?

% TODO[S] notre = ?

\newspeak est conçu pour l'analyse statique par interprétation abstraite. Il a
donc une vue de bas niveau sur les programmes. Par exemple, aucune distinction
n'est faite entre l'accès à un champ et l'accès à un élément d'un tableau (tous
deux sont traduits par un décalage numérique depuis le début de la zone
mémoire). De plus, les unions et les structures sont regroupées sous forme des
types \enquote{régions} qui associent à un décalage un type de champ. Pour
supprimer ces ambiguïtés, il faut s'interfacer dans les structures internes de
\ctonewspeak, où les informations nécessaires sont encore présentes.

Ensuite, les différents fichiers sont liés ensemble. Cette étape consiste
principalement à s'assurer que les hypothèses faites par les différentes unités
de compilation sont cohérentes entre elles. Les objets marqués \texttt{static},
invisibles à l'extérieur de leur unité de compilation, sont renommés afin qu'ils
aient un nom globalement unique.

% TODO[S] on dirait que tu fais ça dans c2npk

Enfin, l'implantation d'un algorithme d'inférence pour les systèmes de types
décrits dans les chapitres~\ref{cha:typbase} et~\ref{cha:qualifs} est assez
simple. Puisqu'ils sont suffisamment proches du lambda calcul simplement typé, on
peut utiliser une variante de l'algorithme W de Damas et
Milner~\cite{DamasMilner}.

Cela repose sur l'unification: on dispose d'une fonction permettant de créer des
inconnues de type, et d'une fonction pour unifier deux types partiellement
inconnus. Cet algorithme sera décrit dans la section~\ref{sec:unif}. En
pratique, on utilise l'optimisation classique qui consiste à se
reposer sur le partage de références pour réaliser l'unification, plutôt que de
faire des substitutions explicites. Puisque ces systèmes de types sont
monomorphes, on présente une erreur si des variable de type libres sont
présentes.

À la fin de cette étape, on obtient soit un programme complètement annoté, soit
une erreur de type.

\section{Algorithme d'unification}
\label{sec:unif}

On présente ici la fonction \texttt{unify}. Celle-ci prend en entrée deux
représentations de types pouvant contenir des inconnues de la forme \texttt{Var
n}, et retourne une liste de couples $(n, t)$ indiquant les substitutions à
faire.

%TODO[S] dire d'où vient le Var n

Cet algorithme (décrit en pseudo-code ML en figure~\ref{fig:algo-unif}) prend un
chemin différent selon la forme des deux types d'entrée:

\changed{Passage en pseudocode}

\begin{figure}%{{{

% {{{
% http://tex.stackexchange.com/questions/53357/switch-cases-in-algorithmic
% New definitions
\algnewcommand\algorithmicmatch{\textbf{match}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicwith{\textbf{with}}
\algnewcommand\algorithmicto{\textbf{to}}
\algnewcommand\ErrorCul{\textbf{erreur}}
\algnewcommand\Error{\State \ErrorCul}
\algnewcommand\algorithmicnil{[~]}
\algnewcommand\Var[1]{\textsc{Var}~{#1}}
% New "environments"
\algdef{SE}[MATCH]{Match}{EndMatch}[1]
    {\algorithmicmatch\ (#1)\ \algorithmicwith}
    {\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]
    {|~\ #1\ $⇒$}
    {\algorithmicend\ \algorithmiccase}%
\algtext*{EndMatch}%
\algtext*{EndCase}%

\algrenewcommand\algorithmicindent{3em}
%}}}

\begin{algorithmic}[1]
    \Function{unify}{$t_a, t_b$}
    \Match{$t_a, t_b$}
        \Case{$\Var{n_a}, \Var{n_b}$}
            \If{$n_a = n_b$}
                \State \Return{\algorithmicnil}
            \Else
                \State \Return{$[(n_a, t_b)]$}
            \EndIf
        \EndCase

        \Case{$\Var{n_a}, t_b$}
            \If{\Call{occurs}{$n_a, t_b$}}
                \Error
            \EndIf
            \State \Return{$[(n_a, t_b)]$}
        \EndCase

        \Case{$t_a, \Var{n_b}$}
            \Return{\Call{unify}{$t_b, t_a$}}
        \EndCase

        \Case{$\tInt, \tInt$}
            \Return{\algorithmicnil}
        \EndCase

        \Case{$\tFloat, \tFloat$}
            \Return{\algorithmicnil}
        \EndCase

        \Case{$a[~], b[~]$}
            \Return{\Call{unify}{$a, b$}}
        \EndCase

        \Case{$\ptrK{a}, \ptrK{b}$}
            \Return{\Call{unify}{$a, b$}}
        \EndCase

        \Case{$\ptrU{a}, \ptrU{b}$}
            \Return{\Call{unify}{$a, b$}}
        \EndCase

        \Case{$(l_a) → r_a, (l_b) → r_b$}
            \State $r \gets$ \Call{unify}{$r_a, r_b$}
            \State $n \gets$ \Call{length}{$l_a$}
            \If {\Call{length}{$l_b$} $≠ n$}
                \Error
            \EndIf
            \For{$i = 0$ \algorithmicto{} $n-1$}
            \State $r \gets r~∪$ \Call{unify}{$l_a[i], l_b[i]$}
            \EndFor
            \State \Return{r}
        \EndCase

        \Case{$\_$}
            \ErrorCul
        \EndCase

    \EndMatch
    \EndFunction
\end{algorithmic}

\caption{Algorithme d'unification}
\label{fig:algo-unif}
\end{figure}%}}}

\begin{itemize}

\item si les deux types sont inconnus (de la forme \texttt{Var n}), on substitue
l'un par l'autre.

\item si un type est inconnu et pas l'autre, il faut de la même manière faire
une substitution.
Mais en faisant ça inconditionnellement, cela peut poser problème:
par exemple en tentant d'unifier \texttt{a} avec \verb!Ptr(a)! on pourrait
créer une substitution cyclique.
Pour éviter cette situation, il suffit de s'assurer que le type inconnu n'est
pas présent dans le type à affecter. C'est le but de la fonction
\texttt{occurs(n, t)} qui calcule si \texttt{Var n} apparaît dans \texttt{t}.

\item si les deux types sont des types de base (comme $\tInt$ ou $\tFloat$)
égaux, on ne fait rien.

\item si les deux types sont des constructeurs de type, il faut que les
constructeurs soient égaux. On unifie en outre leurs arguments deux à deux.

\item dans les autres cas, l'algorithme échoue.

\end{itemize}

Le traitement des types structures est géré dans l'implantation d'une manière
différente de la présentation du chapitre~\ref{cha:lang}. C'est pourquoi elle
n'apparaît pas dans la figure~\ref{fig:algo-unif}. Au lieu d'accéder directement
au type complet $S$ à chaque accès $x.l_S$, on n'obtient qu'un nom de champ à
chaque accès. C'est-à-dire qu'on va par exemple inférer le type $\tStruct{ l:
\tInt ; … }$ où $…$ désigne l'ensemble des champs inconnus. En unifiant
$\tStruct{ a: t_a ; … }$ et $\tStruct{ b: t_b ; … }$ (si $a ≠ b$), on obtient en
sortie que ces deux types sont égaux à $\tStruct{ a: t_a; b: t_b ; … }$. Plus
précisément, pour unifier deux types structure, on étudie les types de leurs
champs. On commence par unifier les types des champs de même nom, et on ajoute à
l'un les champs exclusifs de l'autre. Cela se rapproche du polymorphisme de
rangée~\cite{ocamlObjects} présent dans les langages comme OCaml.

% TODO[E] y a-t-il une variable de rangée?

% TODO[S] plus précisément => ce n'est pas plus précis
% - pourquoi ça marche
% - un ex plus complet
% - à quoi ça sert d'unifier des champs de noms différents?

\added{citation}

\section{Architecture de \ptrtype}
\label{sec:ptrtype-archi}

Cette analyse est implantée dans un outil du nom de \ptrtype{}. Il lit un
programme \newspeak (ou un fichier C), et réalise l'inférence de types. En
sortie, il affiche soit le programme complètement annoté, soit une erreur.

% TODO[S] ça représente combien de lignes de code ptrtype?

Si l'argument passé à \ptrtype{} est un fichier C, il est tout d'abord compilé
vers \newspeak grâce à l'utilitaire \ctonewspeak. Ensuite, les autres passes
travaillent sur une représentation intermédiaire proche de \newspeak, mais où
des étiquettes de type supplémentaires sont ajoutées. Ce type de représentation
intermédiaire est noté \texttt{'a Tyspeak.t}, où \texttt{'a} est le type des
étiquettes. Mais ce n'est qu'un type différent: il s'agit bien de \newspeak.

% TODO[E] Mais...: ??

\added{précision que c'est bien du newspeak}

Le reste de l'outil est résumé dans la fonction
\texttt{process\_npk} (figure~\ref{fig:implem-process}):

\begin{figure}
\insertcode{implem-process.ml}
\caption{Fonction principale de \ptrtype{}}
\label{fig:implem-process}
\end{figure}

\begin{itemize}

\item Grâce à la fonction \verb!convert_unit : Newspeak.t -> unit Tyspeak.t!, on
ajoute des étiquettes \enquote{vides} (toutes égales à \verb!() : unit!).

\item L'ensemble des fonctions du programme est trié topologiquement selon la
    relation~$\preceq$ définie par $f \preceq g \eqdef \enquote{g \textrm{
    apparaît dans la définition de } f}$. Cela est fait en construisant une
    représentation de $\preceq$ sous forme de graphe, puis en faisant un
    parcours en largeur de celui-ci. Pour le moment, les fonctions récursives et
    mutellement récursives ne sont pas supportées.

\item Les annotations extérieures sont alors lues (variable \texttt{exttbl}), ce
  qui permet de créer un environnement initial. Celles-ci permettent par exemple
  de spécifier le type d'une fonction inconnue.

\item Les types de chaque fonction sont inférés, par le biais de la fonction
  suivante:

\begin{Verbatim}
val infer : Newspeak.fid list
         -> Types.simple Env.t
         -> 'a Tyspeak.t
         -> Types.simple Tyspeak.t
\end{Verbatim}

% TODO[S] comms: liste triée de fcts à typer
% environnement initial
% prog à analyser

\item S'il n'y a pas d'erreurs, le programme obtenu, de type
\texttt{Types.simple Tyspeak.t}, est affiché sur le terminal.

\end{itemize}

La fonction appelée par le reste du code, appelée \texttt{unify}, peut
retarder l'unification (figure~\ref{fig:implem-lazy}). Dans ce cas, la paire de
types à unifier est mise dans une liste d'attente qui sera unifiée après le
parcours du programme. Le but est d'instrumenter l'inférence de types afin de
pouvoir en faire une exécution \enquote{pas à pas}.

% TODO[S] appelée dans infer? unify: où est elle? et process_npk ? pas clair

\begin{figure}

\insertcode{unify-main.ml}

\caption{Unification directe ou retardée}
\label{fig:implem-lazy}
\end{figure}

\section{Inférence de types}

L'inférence de types consiste à remplacer les étiquettes de type \texttt{unit}
par des étiquettes de type \texttt{simple} (autrement dit de vraies
représentations de types).

\added{cela permet...}

Cette étape se fait de manière impérative. Cela permet de ne pas avoir à
réaliser de substitutions explicites. À la place, on repose sur le partage et
les références, qui représentent les inconnues de type. Lorsque celles-ci sont
résolues, il suffit de muter une seule fois la référence, et le partage fait que
ce changement sera visible partout. Plus précisément, on peut créer de nouveaux
types avec la fonction \texttt{new\_unknown} et unifier deux types avec la
fonction \texttt{unify}. Leurs types sont:

\begin{verbatim}
val new_unknown : unit -> Types.simple
val unify : Types.simple -> Types.simple -> unit
\end{verbatim}

La fonction \texttt{infer} s'appuie sur un ensemble de fonctions récursivement
définies portant sur chaque type de fragment: \texttt{infer\_fdec} pour les
déclarations de fonction, \texttt{infer\_exp} pour les expressions,
\texttt{infer\_stmtkind} pour les instructions, etc. Grâce au
lemme~\ref{lemma:inversion}, on sait quelle règle appliquer en fonction de
l'expression ou instruction considérée. Notons que, même si le programme
\newspeak est décoré d'informations de types (celles qui existent dans le
programme C), elles ne sont pas utilisées.

Les règles de typage sont implantées par \texttt{new\_unknown} et
\texttt{unify}. Par exemple, pour typer une déclaration (qui n'a pas de valeur
initiale en \newspeak), on crée un nouveau type \texttt{t0}. On étend
l'environnement courant avec cette nouvelle association et, sous ce nouvel
environnement, on type le bloc de portée de la déclaration
(figure~\ref{fig:implem-unif-stmt}).

\begin{figure}[h] %{{{

\insertcode{infer-unif-stmt.ml}

\caption{Inférence des déclarations de variable et appels de
         fonction}

\label{fig:implem-unif-stmt}
\end{figure}%}}}

De même, pour typer un appel de fonction, on infère le type de ses arguments et
valeurs gauches de retour. On obtient également le type de la fonction (à partir
du type de la fonction présent dans l'environnement, ou du type du pointeur de
fonction qui est déréférencé), et on unifie ces deux informations.

On peut donner quelques autres exemples. Pour additionner deux flottants, on
unifie leur type avec \tFloat. Le résultat est également de type \tFloat. Cela
correspond à la règle \textsc{Op-Float}.

\begin{verbatim}
let infer_binop op (_, a) (_, b) =
  match op with
    (* [...] *)
    | N.PlusF _ ->
        unify a Float;
        unify b Float;
        Float
\end{verbatim}

Pour prendre l'adresse d'une variable, la règle \textsc{Addr} s'applique: on
prend le type de la valeur gauche et on construit un pointeur noyau à partir de
lui.

\begin{verbatim}
| T.AddrOf lv ->
    let lv' = infer_lv env lv in
    let ty = lval_type env lv in
    (T.AddrOf lv', Ptr (Kernel, ty))
\end{verbatim}

\label{page:qualifs-pas-qualifs}
Notons que, dans la représentation des types pointeurs, c'est une étiquette
séparée qui tient compte de qui contrôle la valeur. Cela vient du fait qu'une
première présentation de ce système de types utilisait des qualificateurs
explicites (sur les pointeurs uniquement), avant de passer à deux types
indépendants. Cette représentation a néanmoins l'avantage de permettre la
factorisation de code.

% TODO[S] ?
% TODO[E] virer les mentions de la première ver

Enfin, pour déréférencer une expression, on unifie tout d'abord son type avec le
type d'un pointeur noyau.

\begin{verbatim}
| T.Deref(e, _sz) ->
    let (_, te) = infer_exp env e in
    let t = new_unknown () in
    unify (Ptr (Kernel, t)) te;
    t
\end{verbatim}

\section{Exemple}

Lançons l'analyse sur un petit exemple:

\begin{verbatim}
int f(int *x) { return (*x + 1); }
\end{verbatim}

L'exécution de notre analyseur affiche un programme complètement annoté:

\begin{verbatim}
 % ptrtype example.c
f : (Ptr (Int)) -> (Int)
Int (example.c:1#4)^f(Ptr (Int) x) {
  (.c:3#4)^!return =(int32)
    (coerce[-2147483648,2147483647]
      ( ( ([(x_Ptr (Int) : Ptr (Int))]32_Int
            : Int
          )
          + (1 : Int)
        ) : Int
      ) : Int
    );
}
\end{verbatim}

% TODO[E] partie perso
% TODO[E] + en avant

L'opérateur \texttt{coerce[a,b]} est un artefact de \newspeak, destiné à
détecter les débordements d'entiers lors d'une analyse de valeurs par
interprétation abstraite. Dans le cas de notre analyse, les valeurs ne sont pas
pertinentes et cet opérateur peut être vu que comme l'identité.

Un exemple de détection d'erreur sera décrit dans la section~\ref{sec:demo-unif}.

\section{Performance}

\added{2 paragraphes sur la complexité théorique}

Comme le problème de l'inférence de types par l'algorithme W est complet pour
DEXPTIME~\cite{mairson}, on peut s'attendre à une complexité exponentielle en la
taille du programme. Cependant, lorsqu'on borne la \enquote{taille} $d$ des
types, celle-ci devient quasi-linéaire~\cite{rta03} ($O(n α(n) + dn)$ où $α$ est
l'inverse de la fonction d'Ackermann).

% TODO md ??!! complet exp

Dans notre cas, on utilise une variante de l'algorithme W pour un langage
particulièrement simple. En particulier il n'y a pas de polymorphisme, ni de
fonctions imbriquées, et les types des valeurs globales sont écrites par le
programmeur, ce qui permet de borner $d$. En effet, sur les exemples testés nous
n'avons pas noté de délai d'exécution notable.

En revanche, la compilation de C vers \newspeak peut être plus coûteuse,
notamment lorsque le fichier d'entrée est de taille importante. Le temps de
traitement est plus long que celui d'un compilateur comme \texttt{gcc} ou
\texttt{clang}, mais reste de l'ordre de quelques secondes. \ctonewspeak a été
utilisé pour compiler des projets de l'ordre du million de lignes de code source
prétraité, et son exécution ne prenait pas plus de quelques minutes.

%TODO[S] plus de temps C->npk que npk->npk annoté?

Les structures internes de \ctonewspeak ont déjà été améliorées, et d'autres
optimisations sont certainement possibles, mais la performance n'est pas
bloquante pour le moment: une fois que le code est compilé, on peut réutiliser
le fichier objet \newspeak pour d'autres analyses. La compilation est donc
relativement rare.

\section*{Conclusion}

Les analyses de typage correspondant aux chapitres~\ref{cha:typbase}
et~\ref{cha:qualifs} ont été implantées sous forme d'un prototype utilisant le
langage \newspeak développé par EADS. Cela permet de réutiliser les phases de
compilation déjà implantées, et d'exprimer les règles de typage sur un langage
suffisament simple.

% TODO[E] EADS: le dire avant

On utilise un algorithme par unification, qui donne une forme simple au
programme d'inférence. Pour chaque expression ou instruction à typer, on
détermine grâce au lemme~\ref{lemma:inversion} quelle règle il faut appliquer.
Ensuite, on génère les inconnues de type nécessaires pour appliquer cette règle
et on indique les contraintes en appelant la fonction d'unification.

Ce prototype, disponible sous license libre sur~\link{penjili}, reste incomplet,
mais il permet de traiter des parties du noyau Linux comme on le verra dans le
chapitre suivant.

% TODO[E] reste incomplet: en quoi
% TODO[E] dire que ct le but (meme en ne traitant qu'ue partie de C)
% TODO[E] dire la taille
% TODO[E] + rajoute un peu

% vim: spelllang=fr
