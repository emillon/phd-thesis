Dans ce chapitre, nous décrivons la mise en œuvre des analyses statiques
précédentes.
Celles-ci ont été décrites sur \langname, qui permet de modéliser des programmes
C bien typables.

Notre but est d'utiliser la représentation intermédiaire \newspeak, développée
par EADS. Cela permet de profiter des nombreux outils existant déjà autour de ce
langage, notamment un compilateur depuis C et un analyseur statique par
interprétation abstraite.

Mais cette représentation utilise un modèle mémoire différent. En effet il
colle finement à celui de C, où des constructions comme les unions empêchent la
sûreté du typage. Définir \langname a précisement pour but de définir un langage
inspiré de C mais sur lequel le typage peut être sûr. Il faudra donc adapter les
règles de typage les chapitres~\ref{cha:typbase} et~\ref{cha:qualifs}. On
reviendra sur cette distinction entre les deux niveaux de sémantique dans la
conclusion de la partie~\ref{part:xp}, page~\pageref{page:ccl-npk-spk}.

On commence par décrire le langage \newspeak. Ensuite, nous décrivons la phase
de compilation, de C à \newspeak, auquel on rajoute ensuite des étiquettes de
types. Celles-ci sont calculées par un algorithme d'inférence de types à la
Hindley-Milner, reposant sur l'unification et le partage de références. Toutes
ces étapes sont implantées dans le langage OCaml~\cite{DAOC}.

Le prototype décrit ici est disponible sur~\link{penjili} sous une license
libre, la \emph{GNU Lesser General Public License}.

\section{\newspeak et chaîne de compilation}
\label{sec:compil}

\newspeak est un langage intermédiaire conçu pour être un bon support d'analyses
statiques, contrairement à des langages conçus pour les programmeurs comme C. Sa
sémantique d'exécution (ainsi qu'une partie des étapes de compilation)
est décrite dans~\cite{newspeak}. Sa syntaxe est donnée dans la
figure~\ref{fig:stx-npk}.

\begin{figure}%{{{

\def\npkstyle#1{\mathrm{#1}}

\begin{align*}
\gramdef{Instruction}{s}
    {\npkstyle{Set} (lv, e, st)}{Affectation}
    {\npkstyle{Copy} (lv, lv, n)}{Copie}
    {\npkstyle{Guard} (e)}{Garde}
    {\npkstyle{Decl} (var, t, blk)}{Déclaration}
    {\npkstyle{Select} (blk, blk)}{Branchement}
    {\npkstyle{InfLoop} (blk)}{Boucle infinie}
    {\npkstyle{DoWith} (blk, x)}{Nommage de bloc}
    {\npkstyle{Goto} (x)}{Saut}
    {\npkstyle{Call} ([(e_i, t_i)], f, [(lv_i, t_i)])}
            {Appel de fonction}
    {END}
\\ \\
\gramdef{Bloc}{blk}
    {[s_i]}{Liste d'instructions}
    {END}
\\ \\
\gramdef{Valeur gauche}{lv}
    {\npkstyle{Local} (x)}{Locale}
    {\npkstyle{Global} (x)}{Globale}
    {\npkstyle{Deref} (e, n)}{Déréférencement}
    {\npkstyle{Shift} (lv, e)}{Décalage}
    {END}
\\ \\
\gramdef{Expression}{e}
    { \npkstyle{CInt} (n) }{Entier}
    { \npkstyle{CFloat} (d)}{Flottant}
    { \npkstyle{Nil} }{ Pointeur nul }
    { \npkstyle{Lval} (lv, t)}{Accès mémoire}
    { \npkstyle{AddrOf} (lv) }{Adresse de variable}
    { \npkstyle{AddrOfFun} (x, [t_i], [t_i])}{Adresse de fonction}
    { \npkstyle{UnOp} (unop, e) }{Opérateur unaire}
    { \npkstyle{BinOp} (binop, e_1, e_2) }{Opérateur binaire}
    {END}
\\ \\
\gramdef{Fonction}{f}
    { \npkstyle{FunId} (x)}{Appel par nom}
    { \npkstyle{FunDeref} (e)}{Appel par pointeur}
    {END}
\\ \\
\gramdef{Type}{t}
    { \npkstyle{Scalar} (st) }{Type scalaire}
    { \npkstyle{Array} (t, n)}{Tableau}
    { \npkstyle{Region} ([(n_i, t_i)], n')}{Structure/union}
    {END}
\\ \\
\gramdef{Type scalaire}{st}
    { \npkstyle{Int} (n) }{Entier}
    { \npkstyle{Float} (n) }{Flottant}
    { \npkstyle{Ptr} }{ Pointeur sur données}
    { \npkstyle{FunPtr}}{ Pointeur sur fonction}
    {END}
\end{align*}
\caption{Syntaxe simplifiée de \newspeak}
\label{fig:stx-npk}
\end{figure}%}}}

La traduction depuis C est faite en trois étapes: prétraitement du code source
par un outil externe, compilation séparée de C prétraité vers des objets
\newspeak{}, puis liaison de ces différentes unités de compilation. Il est aussi
possible de compiler directement du code Ada vers un objet \newspeak{}.

La première étape consiste à prétraiter les fichiers C source avec le logiciel
\texttt{cpp}, comme pour une compilation normale. Cette étape interprète les
directives de prétraitement comme \texttt{\#include}, \texttt{\#ifdef}. À cet
étape, les commentaires sont aussi supprimés.

Une fois cette passe effectuée, le résultat est un ensemble de fichiers C
prétraités; c'est-à-dire des unités de compilation.

Sur cette représentation (du C prétraité), il est possible d'ajouter des
annotations de la forme \texttt{/*!npk [...] */} qui pourront être accessibles
dans l'arbre de syntaxe abstraite des passes suivantes.

À ce niveau, les fichiers sont passés à l'outil \ctonewspeak qui les
traduit vers \newspeak. Comme il sera décrit dans la section~\ref{sec:gnuc}, la
plupart des extensions GNU C sont acceptées en plus du C ANSI. Dans cette étape,
les types et les noms sont résolus, et le programme est annoté de manière à
rendre les prochaines étapes indépendantes du contexte. Par exemple, chaque
déclaration de variable est adjointe d'une description complète du type.

Lors de cette étape, le flot de contrôle est également simplifié
(figure~\ref{fig:flot-controle-simple}). De plus, les constructions ambigües en
C comme \texttt{i = i++} sont transformées pour que leur évaluation se fasse
dans dans un ordre explicite.

\begin{figure}[b]

\begin{SaveVerbatim}{compilnpk}
int32 x;
x =(int32) 0;
do {
    while (1) {
        choose {
            -->
                guard((10 > x_int32));
            -->
                guard(! (10 > x_int32));
                goto lbl1;
        }
        x =(int32) coerce[-2**31,2**31-1] (x_int32 + 1);
    }
} with lbl1: {
}
\end{SaveVerbatim}

\subbottom[Code source C]{
\begin{minipage}{0.23\linewidth}
\insertcode{npk-while.c}
\end{minipage}
}
\vrule\hspace{2pt}
\subbottom[Programme compilé en \newspeak]{
\begin{minipage}{0.7\linewidth}
\BUseVerbatim{compilnpk}
\end{minipage}
}

    \caption{Compilation du flot de contrôle en \newspeak}
    \label{fig:flot-controle-simple}
\end{figure}

Au contraire, \newspeak propose un nombre réduit de constructions. Rappelons que
le but de ce langage est de faciliter l'analyse statique: des constructions
orthogonales permettent donc d'éviter la duplication de règles sémantiques, ou
de code, lors de l'implantation d'un analyseur.

Par exemple, plutôt que de fournir une boucle \emph{while}, une boucle
\emph{do/while} et une boucle \emph{for}, \newspeak fournit une unique boucle
\phx\npkWhile. La sortie de boucle est compilée vers un \npkGoto{}\cite{goto},
qui est toujours un saut vers l'avant (similaire à un \enquote{\emph{break}}
généralisé).

\newspeak est conçu pour l'analyse statique par interprétation abstraite. Il a
donc une vue de bas niveau sur les programmes. Par exemple, aucune distinction
n'est faite entre l'accès à un champ et l'accès à un élément d'un tableau (tous
deux sont traduits par un décalage numérique depuis le début de la zone
mémoire). De plus, les unions et les structures sont regroupées sous forme des
types \enquote{régions} qui associent à un décalage un type de champ. Pour
supprimer ces ambiguïtés, il faut s'interfacer dans les structures internes de
\ctonewspeak, où les informations nécessaires sont encore présentes.

Ensuite, les différents fichiers sont liés ensemble. Cette étape consiste
principalement à s'assurer que les hypothèses faites par les différentes unités
de compilation sont cohérentes entre elles. Les objets marqués \texttt{static},
invisibles à l'extérieur de leur unité de compilation, sont renommés afin qu'ils
aient un nom globalement unique. Cette étape se conclut par la création d'un
fichier \newspeak.

La dernière étape est réalisée dans un autre outil nommé \ptrtype. Elle consiste
en l'implantation d'un algorithme d'inférence pour les systèmes de types décrits
dans les chapitres~\ref{cha:typbase} et~\ref{cha:qualifs} est assez simple.
Puisqu'ils sont suffisamment proches du lambda calcul simplement typé, on peut
utiliser une variante de l'algorithme W de Damas et Milner~\cite{DamasMilner}.

Cela repose sur l'unification: on dispose d'une fonction permettant de créer des
inconnues de type, et d'une fonction pour unifier deux types partiellement
inconnus. Cet algorithme sera décrit dans la section~\ref{sec:unif}. En
pratique, on utilise l'optimisation classique qui consiste à se
reposer sur le partage de références pour réaliser l'unification, plutôt que de
faire des substitutions explicites. Puisque ces systèmes de types sont
monomorphes, on présente une erreur si des variable de type libres sont
présentes.

À la fin de cette étape, on obtient soit un programme complètement annoté, soit
une erreur de type.

\section{Algorithme d'unification}
\label{sec:unif}

On présente ici la fonction \texttt{unify}. Celle-ci prend en entrée deux
représentations de types pouvant contenir des inconnues de la forme \texttt{Var
n}, et retourne une liste de couples $(n, t)$ indiquant les substitutions à
faire.

Cet algorithme (décrit en pseudo-code ML en figure~\ref{fig:algo-unif}) prend un
chemin différent selon la forme des deux types d'entrée:

\changed{Passage en pseudocode}

\begin{figure}%{{{

% {{{
% http://tex.stackexchange.com/questions/53357/switch-cases-in-algorithmic
% New definitions
\algnewcommand\algorithmicmatch{\textbf{match}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicwith{\textbf{with}}
\algnewcommand\algorithmicto{\textbf{to}}
\algnewcommand\ErrorCul{\textbf{erreur}}
\algnewcommand\Error{\State \ErrorCul}
\algnewcommand\algorithmicnil{[~]}
\algnewcommand\Var[1]{\textsc{Var}~{#1}}
% New "environments"
\algdef{SE}[MATCH]{Match}{EndMatch}[1]
    {\algorithmicmatch\ (#1)\ \algorithmicwith}
    {\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]
    {|~\ #1\ $⇒$}
    {\algorithmicend\ \algorithmiccase}%
\algtext*{EndMatch}%
\algtext*{EndCase}%

\algrenewcommand\algorithmicindent{3em}
%}}}

\begin{algorithmic}[1]
    \Function{unify}{$t_a, t_b$}
    \Match{$t_a, t_b$}
        \Case{$\Var{n_a}, \Var{n_b}$}
            \If{$n_a = n_b$}
                \State \Return{\algorithmicnil}
            \Else
                \State \Return{$[(n_a, t_b)]$}
            \EndIf
        \EndCase

        \Case{$\Var{n_a}, t_b$}
            \If{\Call{occurs}{$n_a, t_b$}}
                \Error
            \EndIf
            \State \Return{$[(n_a, t_b)]$}
        \EndCase

        \Case{$t_a, \Var{n_b}$}
            \Return{\Call{unify}{$t_b, t_a$}}
        \EndCase

        \Case{$\tInt, \tInt$}
            \Return{\algorithmicnil}
        \EndCase

        \Case{$\tFloat, \tFloat$}
            \Return{\algorithmicnil}
        \EndCase

        \Case{$a[~], b[~]$}
            \Return{\Call{unify}{$a, b$}}
        \EndCase

        \Case{$\ptrK{a}, \ptrK{b}$}
            \Return{\Call{unify}{$a, b$}}
        \EndCase

        \Case{$\ptrU{a}, \ptrU{b}$}
            \Return{\Call{unify}{$a, b$}}
        \EndCase

        \Case{$(l_a) → r_a, (l_b) → r_b$}
            \State $r \gets$ \Call{unify}{$r_a, r_b$}
            \State $n \gets$ \Call{length}{$l_a$}
            \If {\Call{length}{$l_b$} $≠ n$}
                \Error
            \EndIf
            \For{$i = 0$ \algorithmicto{} $n-1$}
            \State $r \gets r~∪$ \Call{unify}{$l_a[i], l_b[i]$}
            \EndFor
            \State \Return{r}
        \EndCase

        \Case{$\_$}
            \ErrorCul
        \EndCase

    \EndMatch
    \EndFunction
\end{algorithmic}

\caption{Algorithme d'unification}
\label{fig:algo-unif}
\end{figure}%}}}

\begin{itemize}

\item si les deux types sont inconnus (de la forme \texttt{Var n}), on substitue
l'un par l'autre.

\item si un type est inconnu et pas l'autre, il faut de la même manière faire
une substitution.
Mais en faisant ça inconditionnellement, cela peut poser problème:
par exemple en tentant d'unifier \texttt{a} avec \verb!Ptr(a)! on pourrait
créer une substitution cyclique.
Pour éviter cette situation, il suffit de s'assurer que le type inconnu n'est
pas présent dans le type à affecter. C'est le but de la fonction
\texttt{occurs(n, t)} qui calcule si \texttt{Var n} apparaît dans \texttt{t}.

\item si les deux types sont des types de base (comme $\tInt$ ou $\tFloat$)
égaux, on ne fait rien.

\item si les deux types sont des constructeurs de type, il faut que les
constructeurs soient égaux. On unifie en outre leurs arguments deux à deux.

\item dans les autres cas, l'algorithme échoue.

\end{itemize}

Le traitement des types structures est géré dans l'implantation d'une manière
différente de la présentation du chapitre~\ref{cha:lang}. C'est pourquoi elle
n'apparaît pas dans la figure~\ref{fig:algo-unif}. Au lieu d'accéder directement
au type complet $S$ à chaque accès $x.l_S$, on n'obtient qu'un nom de champ à
chaque accès. C'est-à-dire qu'on va par exemple inférer le type $\tStruct{ l:
\tInt ; …X }$ où $…X$ désigne l'ensemble des champs inconnus.

Plus précisément, si on cherche à unifier les types structures
$A = \tStruct{ a_1: t_1 ; … ; a_n: t_n; …X_a }$
et
$B = \tStruct{ b_1: s_1 ; … ; b_m: u_m; …X_b }$,
il faut partitionner l'ensemble des champs en 3: ceux qui apparaissent dans les
deux structures, ceux qui apparaissent dans $A$ mais pas dans $B$, et ceux qui
apparaissent dans $B$ mais pas dans $A$.

\begin{itemize}
    \item Pour tous les champs $l$ tels que $l: a_i ∈ A$ et $l: b_j ∈ B$,
        on unifie $a_i$ et $b_j$.
    \item Pour les champs $l$ qui sont dans $A$ mais pas dans $B$: on ajoute $l$
        à $X_b$.
    \item Pour les champs $l$ qui sont dans $B$ mais pas dans $A$: on ajoute $l$
        à $X_a$.
\end{itemize}

Cela se rapproche du polymorphisme de rangée~\cite{ocamlObjects} présent dans
les langages comme OCaml. À la fin de l'inférence, on considère que la variable
de rangée \enquote{$…X$} est vide. Elle n'apparaît donc pas dans les types.

% TODx ajouter à la figure algo?
% cstrs ::= n ↦ t
%        |  t ∈ X

\added{citation}

\section{Architecture de \ptrtype}
\label{sec:ptrtype-archi}

Cette analyse est implantée dans un outil du nom de \ptrtype{}, d'environ 1600
lignes de code OCaml. Il lit un
programme \newspeak (ou un fichier C), et réalise l'inférence de types. En
sortie, il affiche soit le programme complètement annoté, soit une erreur.

Si l'argument passé à \ptrtype{} est un fichier C, il est tout d'abord compilé
vers \newspeak grâce à l'utilitaire \ctonewspeak. Ensuite, les autres passes
travaillent sur une représentation intermédiaire proche de \newspeak, mais où
des étiquettes de type supplémentaires sont ajoutées. Ce type de représentation
intermédiaire est noté \texttt{'a Tyspeak.t} (pour \emph{typed} \newspeak), où
\texttt{'a} est le type des étiquettes.

\added{précision que c'est bien du newspeak}

Le reste de l'outil est résumé dans la fonction
\texttt{process\_npk} (figure~\ref{fig:implem-process}):

\begin{figure}
\insertcode{implem-process.ml}
\caption{Fonction principale de \ptrtype{}}
\label{fig:implem-process}
\end{figure}

\begin{itemize}

\item Grâce à la fonction \verb!convert_unit : Newspeak.t -> unit Tyspeak.t!, on
ajoute des étiquettes \enquote{vides} (toutes égales à \verb!() : unit!).

\item L'ensemble des fonctions du programme est trié topologiquement selon la
    relation~$\preceq$ définie par $f \preceq g \eqdef \enquote{g \textrm{
    apparaît dans la définition de } f}$. Cela est fait en construisant une
    représentation de $\preceq$ sous forme de graphe, puis en faisant un
    parcours en largeur de celui-ci. Pour le moment, les fonctions récursives et
    mutellement récursives ne sont pas supportées.

\item Les annotations extérieures sont alors lues (variable \texttt{exttbl}), ce
    qui permet de créer un environnement initial. On peut écrire les annotations
    suivantes:

  \begin{center}
    \begin{tabular}{lp{7cm}}
        \toprule
        Annotation & Signification \\
        \midrule
        \texttt{/*!npk f : (Int) -> Int */} &
        \texttt{f} est une fonction prenant comme argument un entier et
        renvoyant un entier.
        \\
        \texttt{/*!npk userptr x*/} &
        \texttt{x} a pour type $\ptrU{a}$, où $a$ est une inconnue de type.
        \\
        \texttt{/*!npk userptr_fieldp p f*/} &
      \texttt{x} a pour type $\{ f: \ptrU{a} ; … \}~*$, où $a$ est une inconnue
      de type. \\
      \bottomrule
    \end{tabular}
  \end{center}

  % TODO[E] portée de a

\item Les types de chaque fonction sont inférés, par le biais de la fonction
  suivante:

\begin{Verbatim}
val infer : Newspeak.fid list   (* liste triée de fonctions à typer *)
         -> Types.simple Env.t  (* environnement initial *)
         -> 'a Tyspeak.t        (* programme à analyser *)
         -> Types.simple Tyspeak.t
\end{Verbatim}

\item S'il n'y a pas d'erreurs, le programme obtenu, de type
\texttt{Types.simple Tyspeak.t}, est affiché sur le terminal.

\end{itemize}

La fonction appelée \texttt{unify}, appelée dans toutes les fonctions
d'inférence, peut retarder l'unification (figure~\ref{fig:implem-lazy}). Dans ce
cas, la paire de types à unifier est mise dans une liste d'attente qui sera
unifiée après le parcours du programme. Le but est d'instrumenter l'inférence de
types afin de pouvoir en faire une exécution \enquote{pas à pas}.

\begin{figure}

\insertcode{unify-main.ml}

\caption{Unification directe ou retardée}
\label{fig:implem-lazy}
\end{figure}

\section{Inférence de types}

L'inférence de types consiste à remplacer les étiquettes de type \texttt{unit}
par des étiquettes de type \texttt{simple} (autrement dit de vraies
représentations de types).

\added{cela permet...}

Cette étape se fait de manière impérative. Cela permet de ne pas avoir à
réaliser de substitutions explicites. À la place, on repose sur le partage et
les références, qui représentent les inconnues de type. Lorsque celles-ci sont
résolues, il suffit de muter une seule fois la référence, et le partage fait que
ce changement sera visible partout. Plus précisément, on peut créer de nouveaux
types avec la fonction \texttt{new\_unknown} et unifier deux types avec la
fonction \texttt{unify}. Leurs types sont:

\begin{verbatim}
val new_unknown : unit -> Types.simple
val unify : Types.simple -> Types.simple -> unit
\end{verbatim}

La fonction \texttt{infer} s'appuie sur un ensemble de fonctions récursivement
définies portant sur chaque type de fragment: \texttt{infer\_fdec} pour les
déclarations de fonction, \texttt{infer\_exp} pour les expressions,
\texttt{infer\_stmtkind} pour les instructions, etc. Grâce au
lemme~\ref{lemma:inversion}, on sait quelle règle appliquer en fonction de
l'expression ou instruction considérée. Notons que, même si le programme
\newspeak est décoré d'informations de types (celles qui existent dans le
programme C), elles ne sont pas utilisées.

Les règles de typage sont implantées par \texttt{new\_unknown} et
\texttt{unify}. Par exemple, pour typer une déclaration (qui n'a pas de valeur
initiale en \newspeak), on crée un nouveau type \texttt{t0}. On étend
l'environnement courant avec cette nouvelle association et, sous ce nouvel
environnement, on type le bloc de portée de la déclaration
(figure~\ref{fig:implem-unif-stmt}).

\begin{figure}[h] %{{{

\insertcode{infer-unif-stmt.ml}

\caption{Inférence des déclarations de variable et appels de
         fonction}

\label{fig:implem-unif-stmt}
\end{figure}%}}}

De même, pour typer un appel de fonction, on infère le type de ses arguments et
valeurs gauches de retour. On obtient également le type de la fonction (à partir
du type de la fonction présent dans l'environnement, ou du type du pointeur de
fonction qui est déréférencé), et on unifie ces deux informations.

On peut donner quelques autres exemples. Pour additionner deux flottants, on
unifie leur type avec \tFloat. Le résultat est également de type \tFloat. Cela
correspond à la règle \textsc{Op-Float}.

\begin{verbatim}
let infer_binop op (_, a) (_, b) =
  match op with
    (* [...] *)
    | N.PlusF _ ->
        unify a Float;
        unify b Float;
        Float
\end{verbatim}

Pour prendre l'adresse d'une variable, la règle \textsc{Addr} s'applique: on
prend le type de la valeur gauche et on construit un pointeur noyau à partir de
lui.

\begin{verbatim}
| T.AddrOf lv ->
    let lv' = infer_lv env lv in
    let ty = lval_type env lv in
    (T.AddrOf lv', Ptr (Kernel, ty))
\end{verbatim}

Enfin, pour déréférencer une expression, on unifie tout d'abord son type avec le
type d'un pointeur noyau.

\begin{verbatim}
| T.Deref(e, _sz) ->
    let (_, te) = infer_exp env e in
    let t = new_unknown () in
    unify (Ptr (Kernel, t)) te;
    t
\end{verbatim}

\section{Exemple}

Lançons l'analyse sur un petit exemple:

\begin{verbatim}
int f(int *x) { return (*x + 1); }
\end{verbatim}

L'exécution de notre analyseur affiche un programme complètement annoté:

\begin{verbatim}
 % ptrtype example.c
     1	f : (KPtr (Int)) -> (Int)
     2	Int (example.c:1#4)^f(KPtr (Int) x) {
     3	  (.c:3#4)^!return =(int32)
     4	    (coerce[-2147483648,2147483647]
     5	      ( ( ([(x_KPtr (Int) : KPtr (Int))]32_Int
     6	            : Int
     7	          )
     8	          + (1 : Int)
     9	        ) : Int
    10	      ) : Int
    11	    );
    12	}
\end{verbatim}

\begin{itemize}
    \item Ligne 1: le type inféré de la fonction \texttt{f} est affiché. Il est
        calculé entièrement en fonction des opérations effectuées, on n'utilise
        pas les étiquettes de type du programme.

    \item Ligne 2: le code de la fonction est affiché. Les indications de la
        forme \texttt{(F:L\#C)\^{}X} correspondent à la déclaration d'une
        variable X, dans le fichier F, ligne L et colonne C.

    \item Ligne 3: en \newspeak, la valeur de retour est une variable qui est
        affectée. On sépare ainsi le flot de données (définir la valeur de
        retour) du flot de contrôle (sortir de la fonction). C'est un équivalent
        de la variable $\vRet$ introduite pour le typage des fonctions
        (page~\pageref{sec:typ-fun}). L'affectation est notée \texttt{=(int32)}
        car en \newspeak elle est décorée du type des opérandes. Cette
        information n'est pas utilisée dans l'inférence de types.

    \item Ligne 4: l'opérateur \texttt{coerce[a,b]} sert à détecter les
        débordements d'entiers lors d'une analyse de valeurs par interprétation
        abstraite. Dans le cas de notre analyse, les valeurs ne sont pas
        pertinentes et cet opérateur peut être vu que comme l'identité.

    \item Ligne 5: le déréférencement d'une valeur gauche \texttt{e} est noté
        \texttt{[e]\_n}. Il est annoté par la taille de l'opérande (32 bits
        ici). De plus, l'accès à une valeur gauche (pour la transformer en
        expression) est annoté par son type, ce qui explique la verbosité de
        cette ligne.

    \item les autres lignes sont des étiquettes de type inférées sur les
        expressions $1$, $*x$, $1$, $*x + 1$ et la valeur de retour
        $\mathrm{coerce}[-2^{31},2^{31}-1](*x + 1)$.

\end{itemize}

Un exemple de détection d'erreur sera décrit dans la section~\ref{sec:demo-unif}.

\section{Performance}

\added{2 paragraphes sur la complexité théorique}

Même s'il est simple en apparence, le problème de l'inférence de types par
l'algorithme W est EXP-complet~\cite{mairson}, c'est-à-dire que les algorithmes
efficaces ont une complexité exponentielle en la taille du programme. Cependant,
lorsqu'on borne la \enquote{taille} des types, celle-ci devient
quasi-linéaire~\cite{rta03}, ce qui signifie qu'il n'y a pas de problème de
performance à attendre.

Dans notre cas, on utilise une variante de l'algorithme W pour un langage
particulièrement simple. En particulier il n'y a pas de polymorphisme, ni de
fonctions imbriquées, et les types des valeurs globales sont écrites par le
programmeur. Cela permet permet de borner leur taille. En pratique, sur les
exemples testés nous n'avons pas noté de délai d'exécution notable.

En revanche, la compilation de C vers \newspeak peut être plus coûteuse,
notamment lorsque le fichier d'entrée est de taille importante. Le temps de
traitement est plus long que celui d'un compilateur comme \texttt{gcc} ou
\texttt{clang}. \ctonewspeak a été utilisé pour compiler des projets de l'ordre
du million de lignes de code source prétraité, et son exécution ne prenait pas
plus de quelques minutes.

À titre d'illustration, nous avons mesuré les performances de \ctonewspeak et
\ptrtype sur l'exemple \enquote{Blackfin} du chapitre suivant. Celui consiste en
un fichier prétraité de 853 lignes de code C. Exécuter 1000 fois \ctonewspeak
sur ce fichier prend 36.3 secondes, alors qu'exécuter 1000 fois \ptrtype sur le
fichier \newspeak résultant ne dure que 8.1 secondes (pour comparaison, lancer
1000 fois \texttt{/bin/true}, commande qui ne fait rien, prend 1.6 seconde).

Les structures internes de \ctonewspeak ont déjà été améliorées, et d'autres
optimisations sont certainement possibles, mais la performance n'est pas
bloquante pour le moment: une fois que le code est compilé, on peut réutiliser
le fichier objet \newspeak pour d'autres analyses. La compilation est donc
relativement rare.

\section*{Conclusion}

Les analyses de typage correspondant aux chapitres~\ref{cha:typbase}
et~\ref{cha:qualifs} ont été implantées sous forme d'un prototype utilisant le
langage \newspeak développé par EADS. Cela permet de réutiliser les phases de
compilation déjà implantées, et d'exprimer les règles de typage sur un langage
suffisament simple.

On utilise un algorithme par unification, qui donne une forme simple au
programme d'inférence. Pour chaque expression ou instruction à typer, on
détermine grâce au lemme~\ref{lemma:inversion} quelle règle il faut appliquer.
Ensuite, on génère les inconnues de type nécessaires pour appliquer cette règle
et on indique les contraintes en appelant la fonction d'unification.

Ce prototype comporte environ 1600 lignes de code OCaml. Il est disponible sous
license libre sur~\link{penjili}. Il a été pensé pour traiter un type de code
particulier, à savoir le noyau Linux. On montre dans le chapitre suivant que cet
objectif est atteint, puisqu'il permet de détecter plusieurs bugs.

% vim: spelllang=fr
