Dans ce chapitre, nous enrichissons le langage défini dans le
chapitre~\ref{cha:lang} d'un système de types. Celui-ci permet de séparer les
programmes bien formés, comme celui de la figure~\ref{fig:progwf:good} des
programmes mal formés comme celui de la figure~\ref{fig:progwf:bad}.

\begin{SaveVerbatim}[]{VerbProgGood}
f()
(x=0)
{
  x = 1
  return x
}
\end{SaveVerbatim}

\begin{SaveVerbatim}[]{VerbProgBad}
f()
(x=0)
{
  x = 1
  return (*x)
}
\end{SaveVerbatim}

\begin{figure}

  \centering

  \subfloat[][Programme bien formé]{
    \label{fig:progwf:good}
    \BUseVerbatim{VerbProgGood}
  }
  \hspace{2cm}
  \subfloat[][Programme mal formé]{
    \label{fig:progwf:bad}
    \BUseVerbatim{VerbProgBad}
  }

  \caption{Programmes bien et mal formés}
  \label{fig:progwf}

\end{figure}

Le but d'un tel système de types est de rejeter les programmes qui sont
"évidemment faux", c'est à dire dont on peut prouver qu'il provoqueraient des
erreurs à l'exécution dues à une incompatibilité entre valeurs. En ajoutant
cette étape, on restreint la classe d'erreurs qui pourraient bloquer la
sémantique.

\section{Principe}

Le principe est d'associer à chaque construction syntaxique une étiquette
représentant le genre de valeurs qu'elle produira. Dans le programme de la
figure~\ref{fig:progwf:good}, la variable $x$ est initialisée avec la valeur
$0$, c'est donc un entier. Cela signifie que dans tout le programme, toutes les
instances de cette variable
\footnote{Deux variables peuvent avoir le même nom dans deux fonctions
  différentes, par exemple. Dans ce cas il n'y a aucune contrainte particulière
  entre ces deux variables. L'analyse de typage se fait toujours dans un
  contexte précis.
}
porteront ce type. La première instruction est l'affectation de la constante $1$
(entière) à $x$ dont on sait qu'elle porte des valeurs entières, ce qui est donc
correct. Le fait de rencontrer $\iReturn{x}$ permet de conclure que le type de
la fonction est $() → \tInt$.

Dans la seconde fonction, au contraire, l'opérateur $*$ est appliqué à $x$ (le
début de l'analyse est identique et permet de conclure que $x$ porte des valeurs
entières). Or cet opérateur prend un argument d'un type pointeur de la forme
$t*$ et renvoie alors une valeur de type $t$. Ceci est valable pour tout $t$
(\tInt, \tFloat où même $t'*$ : le déréférencement d'un pointeur sur pointeur
donne un pointeur), mais le type de $x$, \tInt, n'est pas de cette forme. Ce
programme est donc mal typé.

\section{Définitions}

\begin{figure}

  \gramlr{Type}{
    \begin{align*}
      t \gramisa & \tInt                         & \textrm{Entier}
      \\ \gramor & \tFloat                       & \textrm{Flottant}
      \\ \gramor & t[]                           & \textrm{Tableau}
      \\ \gramor & t*                            & \textrm{Pointeur}
      \\ \gramor & \tstruct{s}                   & \textrm{Structure}
      \\ \gramor & (t_1, …, t_n) \rightarrow t_r & \textrm{Fonction}
    \end{align*}
  }

  \gramlr{Environnement de typage}{
    \begin{align*}
      Γ \gramisa & []         & \textrm{Environnement vide}
      \\ \gramor & (a, t)::Γ' & \textrm{Extension}
    \end{align*}
  }

  \caption{Types et environnements de typage}

  \label{fig:les-types}

\end{figure}

Les types associés aux expressions sont décrits dans la
figure~\ref{fig:les-types}.

Pour maintenir les contextes de typage, un environnement $Γ$ associe un type à
un ensemble de variables.

Plus précisément, un environnement $Γ$ est une liste de couples (variable,
type).

Par exemple, $(p, \tInt*) ∈ Γ$ permet de typer (sous $Γ$) l'expression $p$ en
$\tInt*$, $*p$ en $\tInt$ et $p +_p 4$ en $\tInt*$.

Le type des fonctions semble faire apparaître un n-uplet $(t_1, …, t_n)$ mais ce
n'est qu'une notation : il n'y a pas de n-uplets de première classe, ils sont
toujours présents dans un type fonctionnel.

\begin{definition}[Typage d'une expression]

  On note de la manière suivante le fait qu'une expression $e$ (telle que
  définie dans la figure~\ref{fig:stx-data}) ait pour type $t$ dans le contexte
  $Γ$.

  \[
    \ty{Γ}{e}{t}
  \]

\end{definition}

\begin{definition}[Typage d'une instruction]

  Les instructions n'ont en revanche pas de type. Mais il est tout de même
  nécessaire de vérifier que troutes les sous-expressions apparaissant dans une
  instruction sont cohérentes ensemble.

  On note de la manière suivante le fait que sous l'environnement $Γ$
  l'instruction $i$ est bien typée :

  \[
    \tyi{Γ}{i}
  \]

\end{definition}

\begin{definition}[Typage d'une phrase]

  De par leur nature séquentielle, les phrases qui composent un programme
  altèrent l'environnement de typage. Par exemple, la déclaration d'une variable
  globale ajoute une valeur dans l'environnement.

  On note

  \[
    \typh{Γ}{p}{Γ'}
  \]

  si le typage de la phrase $p$ transforme l'environnement $Γ$ en $Γ'$.

  On étend cette notation aux suites de phrases :

  \[
    \begin{cases}
      \typhstar{Γ}{[]}{Γ}  \\
      \typhstar{Γ}{p::ps}{Γ'} \mbox{ si }
        ∃ Γ'',
            \begin{cases}
              \typh{Γ}{p}{Γ''}  \\
              \typhstar{Γ''}{ps}{Γ'}
            \end{cases}
    \end{cases}
  \]

\end{definition}

\begin{definition}[Typage d'un programme]

  Un programme est bien typé si on peut typer sa suite de phrases en partant
  d'un environnement vide. C'est à dire s'il existe un environnement final $Γ_f$
  tel que

  \[
    \typhstar{[]}{P}{Γ_f}
  \]

  Cela est indépendant de tout environnement ; on note alors :

  \[
    ⊢ P
  \]

\end{definition}

\section{Expressions}

\subsection*{Littéraux}

Le typage des littéraux numériques ne dépend pas de l'environnement de typage :
ce sont toujours des entiers ou des flottants.

\begin{mathpar}

  \disprule{Cst-Int}

  \disprule{Cst-Float}

\end{mathpar}

Le pointeur nul, quant à lui, est compatible avec tous les types pointeur.

\begin{mathpar}
  \disprule{Cst-Null}
\end{mathpar}

Enfin, le littéral unité a le type $\tUnit$.

\begin{mathpar}
  \disprule{Cst-Unit}
\end{mathpar}

\subsection*{Left-values}

Rappelons que l'environnement de typage $Γ$ contient le type des variables
accessibles du programme. Le cas où la left-value à typer est une variable est
donc direct : il suffit de retrouver son type dans l'environnement.

\begin{mathpar}
  \disprule{Lv-Var}
\end{mathpar}

Dans le cas d'un déréférencement, on commence par typer la left-value
déréférencée. Si elle a un type pointeur, la valeur déréférencée est du type
pointé.

\begin{mathpar}
  \disprule{Lv-Deref}
\end{mathpar}

Pour une left-value indexée (l'accès à tableau), on s'assure que l'indice soit
entier, et que la left-value a un type tableau : le type de l'élement est encore
une fois le type de base du type tableau ($t$ pour $t[]$).

\begin{mathpar}
  \disprule{Lv-Index}
\end{mathpar}

\begin{mathpar}
  \disprule{Lv-Field}
\end{mathpar}

% TODO

\subsection*{Opérateurs}

Un certain nombre d'opérations est possible sur le type \tInt.

\begin{mathpar}
  \disprule{Op-Int}
\end{mathpar}

De même sur \tFloat.

\begin{mathpar}
  \disprule{Op-Float}
\end{mathpar}

Les opérateurs de comparaison peuvent s'appliquer à deux opérandes qui sont d'un
type qui supporte l'égalité. Ceci est représenté par un jugement
$\textsc{Eq}(t)$ qui est vrai pour les types \tInt, \tFloat et pointeurs. Les
opérateurs $=$ et $≠$ renvoient alors un \tInt.

\begin{mathpar}
\disprule{Eq-Num}

\disprule{Eq-Ptr}

\disprule{Eq-Array}

\disprule{Op-Eq}
\end{mathpar}

%TODO Eq-Struct

Les comparaisons sont plus restrictives, et ne s'appliquent qu'aux types
primitifs (on ne peut pas comparer deux pointeurs, ou deux tableaux).

\begin{mathpar}
  \disprule{Op-Comparable}
\end{mathpar}

% TODO extensions aux structs et tableaux

Les opérateurs unaires "$+$" et "$-$" appliquent aux \tInt, et leurs équivalents
"$+.$" et "$-.$" aux \tFloat.

\begin{mathpar}
\disprule{Unop-Plus-Int}
\and
\disprule{Unop-Plus-Float}

\disprule{Unop-Minus-Int}
\and
\disprule{Unop-Minus-Float}
\end{mathpar}

Les opérateurs de négation unaires, en revanche, ne s'appliquent qu'aux
entiers.

\begin{mathpar}
  \disprule{Unop-Not}
\end{mathpar}

L'arithmétique de pointeurs préserve le type des pointeurs.

\begin{mathpar}
  \disprule{Ptr-Arith}
\end{mathpar}

\subsection*{Autres expressions}

Prendre l'adresse d'une left-value rend un type pointeur sur le type de
celle-ci.

\begin{mathpar}
  \disprule{Addr}
\end{mathpar}

Pour typer une affectation, on vérifie que la left-value (à gauche) et
l'expression (à droite) ont le même type. C'est alors le type résultat de
l'expression d'affectation.

\begin{mathpar}
  \disprule{Set}
\end{mathpar}

Un littéral tableau a pour type $t[]$ où $t$ est le type de chacun de ses
éléments.

\begin{mathpar}
  \disprule{Array}
\end{mathpar}

Pour qu'un littéral de structure soit bien typé, il faut que chacun de ses noms
de champs corresponde à un même nom de type structure, avec le bon type pour
chaque champ.

\begin{mathpar}
  \disprule{Struct}
\end{mathpar}

Pour typer un appel de fonction, on s'assure que la fonction a bien un type
fonctionnel. On type alors chacun des arguments avec le type attendu. Le
résultat est du type de retour de la fonction.

\begin{mathpar}
  \disprule{Call}
\end{mathpar}

\section{Instructions}

La séquence est simple à traiter : l'instruction vide est toujours bien typée,
et la suite de deux instructions est bien typée si celles-ci le sont également.

\begin{mathpar}
  \disprule{Pass}

  \disprule{Seq}
\end{mathpar}

Une instruction constituée d'une expression est bien typée si celle-ci peut être
typée dans ce même contexte.

\begin{mathpar}
  \disprule{Exp}
\end{mathpar}

Les constructions de contrôle sont bien typées si leurs sous-instructions sont
bien typées, et si la condition est d'un type entier.

\begin{mathpar}
  \disprule{If}

  \disprule{While}
\end{mathpar}

\section{Fonctions}

Le typage des fonctions fait intervenir une variable virtuelle $\vRet$. Cela
revient à typer l'instruction $\iReturn{e}$ comme $\vRet ← e$.

\begin{mathpar}
  \disprule{Return}
\end{mathpar}

Pour typer une définition de fonction, on commence par créer un nouvel
environnement de typage $Γ'$ obtenu par la suite d'opérations suivantes :

\begin{itemize}
\item
  on enlève (s'il existe) le couple $\vRet : t_f$ correspondant à la
  valeur de retour de la fonction appelante
\item
  on ajoute les types des arguments $a_i : t_i$
\item
  on ajoute les types des variables locales $l_i : t'_i$
\item
  on ajoute le type de la valeur de retour de la fonction appelée,
  $\vRet : t$
\end{itemize}

Il reste alors à vérifier que les initialiseurs $e_i$ ont le bon type $t'_i$ et
que le corps de la fonction est bien typé sous $Γ'$. Le type de la fonction est
alors $(t_1, …, t_n) → t$.

\begin{mathpar}
  \disprule{Fun}
\end{mathpar}

\section{Phrases}

L'évaluation d'une expression est le cas le plus simple. En effet, il y a juste
à vérifier que celle-ci est bien typable (avec ce type) dans l'environnement de
départ. L'environnement n'est pas modifié.

\begin{mathpar}
  \disprule{Ph-Exp}
\end{mathpar}

La déclaration d'une variable globale commence de la même manière, mais on
enrichit l'environnement de cette nouvelle valeur.

\begin{mathpar}
  \disprule{Ph-Var}
\end{mathpar}

\begin{mathpar}
  \disprule{Ph-Struct}
\end{mathpar}

% TODO

\section{Sûreté du typage}

Comme dit l'adage :

\begin{quote}
"Well-typed programs don't go wrong." (Robin Milner)
\end{quote}

C'est à dire qu'un programme bien typé possède des propriétés de sûreté.

\paragraph{Progrès :} l'évaluation d'un terme bien typé ne reste pas bloquée;
il y a toujours une règle qui s'applique.

\paragraph{Préservation :} l'évaluation d'un terme bien typé produit un terme
bien typé.

Puisqu'il s'agit de propriétés reliant la syntaxe à la sémantique, deux types
d'environnement sont utilisés en même temps. D'une part, les environnement de
typage $Γ$ pour la syntaxe, et d'autre part les environnements mémoire $m$ pour
la sémantique. Il est nécessaire de définir une relation de compatibilité entre
ces deux monde, pour exprimer par exemple qu'un état mémoire contient dans la
variable $x$ un entier.

On commence par énoncer quelques lemmes utiles dans la démonstration de ces
théorèmes.

Les règles précédentes ont la particularité suivante : pour chaque forme
syntaxique, il n'y a souvent qu'une règle qui peut s'appliquer. Cela permet de
déduire quelle règle il faut appliquer pour vérifier (ou inférer) le type d'une
expression.

\begin{lemma}[Inversion] \label{lemma:inversion}

  À partir d'un jugement de typage, on peut en déduire des inforamtions sur les
  types de ses sous-expressions.

\begin{itemize}
\item
  Constantes
  \begin{itemize}
    \item si $Γ ⊢ n : t$, alors $t = \tInt$
    \item si $Γ ⊢ d : t$, alors $t = \tFloat$
    \item si $Γ ⊢ \eNull : t$, alors $∃ t', t = t'*$
    \item si $Γ ⊢ \eUnit : t$, alors $t = \tUnit$
  \end{itemize}

\item Références mémoire :
  \begin{itemize}
    \item
      si $Γ ⊢ x : t$, $x : t ∈ Γ$
    \item
      si $Γ ⊢ *lv : t$, alors $Γ ⊢ lv : t*$
    \item
      si $Γ ⊢ lv[e] : t$, alors $Γ ⊢ lv : t[]$ et $Γ ⊢ e : \tInt$
    \item
      si $Γ ⊢ lv.l : t$, alors $Γ ⊢ lv : \{ l: t ; … \}$
    % TODO structure
  \end{itemize}
\item
  Appel de fonction : si $Γ ⊢ e (e_1, …, e_n) : t$, il existe $(t_1, …, t_n)$
  tels que

  \[
    \begin{cases}
      Γ ⊢ e : (t_1, …, t_n) → t \\
      ∀ i ∈ [1;n], Γ ⊢ e_i : t_i
    \end{cases}
  \]

\item Fonction : si $Γ ⊢ \mathrm{fun} (a_1, …, a_n) ((l_1, e_1), …, (l_p, e_p))
  \{i\} : t$, alors il existe $(t_1, …, t_n)$ et $t'$ tels que $t' = (t_1, …,
  t_n) → t$.

  % TODO ...
\end{itemize}

\end{lemma}

\begin{proof}

  Pour chaque jugement, on considère les règles qui peuvent amener à cette
  conclusion.

\begin{itemize}
\item
  Références mémoire :

  \begin{itemize}

    \item $Γ ⊢ x : t$

      La seule règle de cette forme est \textsc{Lv-Var}. Puisque sa prémisse est
      vraie, on en conclut que $x : t ∈ Γ$.

    \item $Γ ⊢ *φ : t$

      De même, seule la règle \textsc{Lv-Deref} convient. On en conclut que $Γ ⊢ φ : t*$.

    \item $Γ ⊢ φ[] : t$

      Idem avec \textsc{Lv-Index}.

    \item $Γ ⊢ φ.l : t$

      $Γ ⊢ φ : \{ l: t ; … \}$ %TODO sûrement différent sans S

  \end{itemize}

\item
  Appel de fonction : pour en arriver à $Γ ⊢ e (e_1, …, e_n) : t$, seule la
  règle \textsc{Call} s'applique, ce qui permet de conclure.

\item Fonction : la seule règle possible pour conclure une dérivation de

  \[
    Γ ⊢ \mathrm{fun} (a_1, …, a_n) ((l_1, e_1), …, (l_p, e_p)) \{i\} : t
  \]
  est \textsc{Fun}.

\end{itemize}
\end{proof}

Il est aussi possible de réaliser l'opération inverse : à partir du type d'une
valeur, on peut déterminer sa forme syntaxique. C'est bien sûr uniquement
possible pour les valeurs, pas pour n'importe quelle expression (par exemple
l'expression $x$ (variable) peut avoir n'importe quel type $t$ dans le contexte
$Γ = x:t$).

\begin{lemma}[Formes canoniques] \label{lemma:canon}

  Il est possible de déterminer la forme syntaxique d'une valeur étant donné son
  type.

  \begin{itemize}
  \item si $Γ ⊢ v : \tInt$, $v = n$.
  \item si $Γ ⊢ v : \tFloat$, $v = d$.
  \item si $Γ ⊢ v : \tUnit$, $v = \eUnit$.
  \item si $Γ ⊢ v : t*$, $v = φ$ ou $v = \eNull$.
  \item si $Γ ⊢ v : (t_1, …, t_n) → t$, $v = f$.
  \item si $Γ ⊢ v : t*$, $v = φ$.
  \item si $Γ ⊢ v : t[]$, $v = \{v_1; …; v_n\}$.
    %TODO structures
  \item si $Γ ⊢ v : (t_1, …, t_n) → t$, $v = \mathrm{fun}
    (a_1, …, a_n) ((l_1, e_1), …, (l_p, e_p))$.
  \end{itemize}

\end{lemma}

Ces lemmes étant établis, on énonce maintenant le théorème de progrès accompagné
d'une notion de compatibilité entre envionnements de typage $Γ$ et états mémoire
$m$.

\begin{definition}[Compatibilité mémoire]

  Soient $Γ$ un environnement de typage et $m = x_1 ↦ v_1, …, x_n ↦ v_n$ un état
  mémoire. On dit que $m$ est compatible avec $Γ$ si

  \[
    ∃ (t_1, …, t_n),
    ∀ i ∈ [1;n],
    \begin{cases} Γ ⊢ x_i : t_i
               \\ Γ ⊢ v_i : t_i
    \end{cases}
  \]

  On note alors $\mcomp{Γ}{m}$.

  % TODO les états mémoires ne sont pas linéaires
  % TODO quid de ce qui n'est pas visible (ie, le tas)

\end{definition}

\begin{theorem}[Progrès]
  \label{thm:progres}

  Supposons que $Γ ⊢ e : t$. Soit $m$ un état mémoire tel que $\mcomp{Γ}{m}$.
  Alors l'un des cas suivant est vrai :

\begin{itemize}
  \item $∃ v, e = v$
  \item $∃ (e', m'), \mcomp{Γ}{m'} ∧ \mm{m}{e}{m'}{e'}$
  \item $∃ Ω ∈ \{Ω_{div},Ω_{array},Ω_{ptr}\}, \msi{m}{e} → Ω$
\end{itemize}

  C'est à dire, soit :

\begin{itemize}
  \item $e$ est complètement évaluée
  \item un pas d'évaluation préservant la compatibilité mémoire est possible
  \item une erreur de division, tableau ou pointeur se produit
\end{itemize}

\end{theorem}

\begin{proof}

  On procède par induction sur la dérivation de $Γ ⊢ e : t$, et plus précisément
  sur la dernière règle utilisée.

  \paragraph{\textsc{Cst-Int} :} % {{{
$e$ est alors de la forme $n$, qui est une valeur.
%}}}
  \paragraph{\textsc{Cst-Float} :} % {{{
$e$ est alors de la forme $d$, qui est une valeur.
%}}}
  \paragraph{\textsc{Cst-Null} :} % {{{
$e$ est alors égale à $\eNull$, qui est une valeur.
%}}}
  \paragraph{\textsc{Cst-Unit} :}%{{{
$e$ est alors égale à \eUnit, qui est une valeur.
%}}}
\paragraph{\textsc{Lv-Var} :}%{{{

Puisque $(x, t) ∈ Γ$ $\mcomp{Γ}{m}$, il existe $(x ↦ v) ∈ m$. La règle
d'évaluation \textsc{Phi-Var} s'applique donc.

% TODO prouver le coup du lookup
%}}}
\paragraph{\textsc{Lv-Deref} :}%{{{

  Appliquons l'hypothèse de récurrence à $lv$ (vu en tant qu'expression).

\begin{itemize}
\item
  $lv = v$. Puisque $Γ ⊢ v : t*$, on déduit du
  lemme~\ref{lemma:canon} que $v = φ$ ou $v = \eNull$.

  Dans le premier cas, la règle \textsc{Phi-Deref} s'applique :
  $\mms{e}{\widehat{*}φ}$.
  Dans le second, puisque $\msi{m}{*\eNull} → Ω_{ptr}$, on a
  $\msi{m}{e} → Ω_{ptr}$.

\item
  $\mm{m}{lv}{m'}{e'}$.
  De \textsc{Ctx} avec $C = *\ctxEmpty$, on obtient
  $\mm{m}{e}{m'}{*e'}$.

\item
  $\msi{m}{lv} → Ω$.
  En appliquant \textsc{Eval-Err} avec $C = *\ctxEmpty$, on obtient
  $\msi{m}{e} → Ω$.

\end{itemize}

% }}}
\paragraph{\textsc{Lv-Index} :} % %{{{

De même, on applique l'hypothèse de récurrence à $lv$.

\begin{itemize}
\item $lv = v$.

Comme $Γ ⊢ v : t[]$, on déduit du lemme~\ref{lemma:canon} que
$v = \{v_1; …; v_p\}$.
Appliquons l'hypothèse de récurrence à $e$.

\begin{itemize}
\item $e = v'$. Puisque $Γ ⊢ e : \tInt$, on réapplique le
lemme~\ref{lemma:canon} et $v' = n$. Deux cas sont à distinguer :
si $n ∈ [0;p-1]$, la règle \textsc{Phi-Array} s'applique et
$\mm{m}{lv[e]}{m}{v_{n+1}}$.
% TODO réécrire bien Phi-Array
% TODO attention à l'off by one
Sinon, $\msi{m}{lv[e]} → Ω_{array}$.
% TODO pourquoi ?

\item $\mm{m}{e}{m'}{e'}$.
En appliquant \textsc{Ctx} avec $C = v[\ctxEmpty]$, on en déduit
\item $\mm{m}{lv[e]}{m'}{lv[e']}$.

\item $\msi{m}{e} → Ω$.
Avec \textsc{Eval-Err} sous ce même contexte,
$\msi{m}{lv[e]} → Ω$
\end{itemize}

\item $\mm{m}{lv}{m'}{e'}$.
On applique alors \textsc{Ctx} avec $C = \ctxEmpty[e]$, et
$\mm{m}{lv[e]}{m'}{e'[e]}$.

\item $\msi{m}{lv} → Ω$.
Toujours avec $C = \ctxEmpty[e]$, de \textsc{Eval-Err} il vient
$\msi{m}{lv[e]} → Ω$.

\end{itemize}
%}}}
\paragraph{\textsc{Lv-Field} :} % TODO
  \paragraph{\textsc{Op-Int} :} % {{{

  Cela implique que $e = e_1~\opbin~e_2$. Par le lemme~\ref{lemma:inversion}, on
  en déduit que $Γ ⊢ e_1 : \tInt$ et $Γ ⊢ e_2 : \tInt$.

  Appliquons l'hypothèse de récurrence sur $e_1$. Trois cas peuvent se produire.

\begin{itemize}

  \item $e_1 = v_1$. On a alors $\mm{m}{e_1}{m'}{v_1}$ avec $m' = m$.

    On applique l'hypothèse de récurrence à $e_2$.

      \begin{itemize}

        \item $e_2 = v_2$ : alors $\mm{m'}{e_2}{m''}{v_2}$ avec $m'' = m$. On
          peut alors appliquer \textsc{Exp-BinOp}.

        \item $∃ (e'_2, m''), \mm{m'}{e_2}{m''}{e'_2}$.

          En appliquant \textsc{Ctx} avec $C = \ctxOp{v_1}{\ctxEmpty}$, on
          en déduit $\mm{m'}{v_1~\opbin~e_2}{m''}{v_1~\opbin~e'_2}$ soit
          $\mm{m}{e}{m''}{v_1~\opbin~e'_2}$.

        \item $\msi{m'}{e_2} → Ω$.
          De \textsc{Eval-Err} avec $C = \ctxOp{v_1}{\ctxEmpty}$
          vient alors $\msi{m}{e} → Ω$.

      \end{itemize}

  \item $∃(e', m'), \mm{m}{e_1}{m'}{e'_1}$.
    En appliquant \textsc{Ctx} avec $C = \ctxOp{\ctxEmpty}{e_2}$, on obtient
    $\mm{m}{e_1~\opbin~e_2}{m'}{e'_1~\opbin~e_2}$, ou
    $\mm{m}{e}{m'}{e'_1~\opbin~e_2}$.

  \item $\msi{m}{e_1} → Ω$.
    D'après \textsc{Eval-Err} avec $C = \ctxOp{\ctxEmpty}{e_2}$, on a
    $\msi{m}{e} → Ω$.

\end{itemize}

% }}}
\paragraph{\textsc{Op-Float} :} % {{{
Ce cas est similaire à \textsc{Op-Int}.
% TODO quid du lemme d'inversion (premiere ligne de Op-Int)?
%}}}
\paragraph{\textsc{Op-Eq} :} %{{{
Ce cas est similaire à \textsc{Op-Int}.
% TODO expand un peu
% TODO quid du lemme d'inversion (premiere ligne de Op-Int)?
%}}}
\paragraph{\textsc{Op-Comparable} :} %{{{
Ce cas est similaire à \textsc{Op-Int}.
% TODO expand un peu
% TODO quid du lemme d'inversion (premiere ligne de Op-Int)?
%}}}
\paragraph{\textsc{Unop-Plus-Int} :} % {{{

Alors $e = +~e_1$. En appliquant l'hypothèse d'induction sur $e_1$ :

\begin{itemize}
\item
  soit $e_1 = v_1$. Alors en appliquant \textsc{Exp-UnOp},
  $\mm{m}{+~v_1}{m}{\widehat{+}~v_1}$, c'est à dire en posant $v =
  \widehat{+}~v_1$, $\mm{m}{e}{m}{v}$.
% TODO écrire la règle
\item
  soit $∃ e'_1, m', \mm{m}{e_1}{m'}{e'_1}$. Alors en appliquant \textsc{Ctx}
avec $C = +~\ctxEmpty$, on obtient $\mm{m}{e}{m'}{e'_1}$.
\item
  soit $\msi{m}{e_1} → Ω$.
  De \textsc{Eval-Err} avec $C = +~\ctxEmpty$ il vient$\msi{m}{e} → Ω$.
\end{itemize}

% }}}
\paragraph{\textsc{Unop-Plus-Float} :} % {{{
Ce cas est similaire à \textsc{Unop-Plus-Int}.
% }}}
\paragraph{\textsc{Unop-Minus-Int} :} % {{{
Ce cas est similaire à \textsc{Unop-Plus-Int}.
% }}}
\paragraph{\textsc{Unop-Minus-Float} :} % {{{
Ce cas est similaire à \textsc{Unop-Plus-Int}.
% }}}
\paragraph{\textsc{Unop-Not} :}%{{{
Ce cas est similaire à \textsc{Unop-Plus-Int}.
%}}}
\paragraph{\textsc{Ptr-Arith} :} % %{{{ TODO

\[ \left( \disprule{Ptr-Arith} \right) \]

%}}}
\paragraph{\textsc{Addr} :} % {{{ TODO

\[ \left( \disprule{Addr} \right) \]

%}}}
\paragraph{\textsc{Set} :} % {{{ TODO

\[ \left( \disprule{Set} \right) \]

%}}}
\paragraph{\textsc{Array} :} % {{{ TODO

\[ \left( \disprule{Array} \right) \]

%}}}
\paragraph{\textsc{Struct} :} % {{{ TODO

\[ \left( \disprule{Struct} \right) \]

%}}}
\paragraph{\textsc{Call} :} % {{{ TODO

\[ \left( \disprule{Call} \right) \]

%}}}
\paragraph{\textsc{Fun} :} % {{{ TODO

\[ \left( \disprule{Fun} \right) \]

%}}}
% TODO vérifier qu'il n'y a pas d'autre règle
% TODO général : que désigne e. Ex avec lv[e]
\end{proof}

\begin{lemma}[Permutation]
  L'ordre dans lequel les variables apparaissent dans un environnement
  n'influe pas sur la relation de typage.

  Pour toute permutation $σ$ de $[1;n]$, on note $σ(x_1 : t_1, …, x_n : t_n) =
  x_{σ(1)} : t_{σ(1)}, … x_{σ(n)} : t_{σ(n)}$.

  Alors : si $Γ ⊢ e : t$ et $Γ' = σ(Γ)$, alors $Γ' ⊢ e : t$.
\end{lemma}

\begin{lemma}[Affaiblissement]
  De même que l'ordre n'influe pas le typage, on peut aussi ajouter des
  associations supplémentaires dans l'environnement sans modifier les typages
  dans cet environnement.

  Si $Γ ⊢ e : t$ et $x ∉ \mathrm{dom}(Γ)$, alors $Γ, x : t' ⊢ e : t$.
\end{lemma}

\begin{lemma}[Substitution]
  Si dans une expression $e$ il apparait une variable $x$ de type $t'$, le
  typage est préservé lorsqu'on remplace ses occurrences par une expression $e'$
  de même type.

  Si $Γ, x : t' ⊢ e : t$ et $Γ ⊢ e' : t'$, alors $Γ ⊢ e [x/e'] : t$.
\end{lemma}

Ces lemmes permettent de prouver le théorème suivant :

\begin{theorem}[Préservation]
  \label{thm:preservation}

  Si une expression est typable et que son évaluation produit une valeur, alors
  cette valeur est du même type que l'expression.

  Si $Γ ⊢ e : t$ et $e → v$ % TODO

  alors $Γ ⊢ v : t$.

\end{theorem}

\section*{TODO}

\begin{itemize}
\item ordre des sections
\item versions $Γ ⊢ i$ des propriétés
\item preuve de progres : état mémoire : doublet/triplet
\item définir les opérations d'ajout/remplacement sur les contextes de typage
\end{itemize}
