\section{Langages intermédiaires}

Le langage C \cite{KandR,AnsiC} a été conçu pour être une sorte d'assembleur
portable, permettant décrire du code indépendamment de l'architecture sur
laquelle il sera compilé. Historiquement, c'est il a permis de créer Unix, et
ainsi de nombreux logiciels bas niveau sont écrits en C. En particulier, il
existe des compilateurs de C vers les différents langages machine pour à peu
près toutes les architectures.

\begin{figure}

  \input{fig/middle-end.tex}

  \caption{Décomposition d'un compilateur : frontends, middle-end, back-ends}
  \label{fig:middle-end}
\end{figure}

Lors de l'écriture d'un compilateur, on a besoin d'un langage intermédiaire qui
fasse l'intermédiaire entre \emph{frontend} et \emph{backend}
(figure~\ref{fig:middle-end}). Avec ce langage, on doit pouvoir (facilement)
réaliser les types d'opérations suivantes :

\begin{itemize}
\item
  compiler ce langage vers un langage machine (interface avec le
  \emph{backend}).
\item
  exprimer des transformations intermédiaires sur cette représentation
  (analyses sémantiques, optimisations, etc).
\end{itemize}

À cause du premier point, un langage comme C est très séduisant, mais
malheureusement il a de nombreux défauts qui font qu'il ne remplit pas le
deuxième. Par exemple, certaines instructions sont ambiguës, et l'ensemble des
opération n'est pas orthogonal (on peut faire la même chose de plusieurs
manières).

Pour pallier ce problème, une première solution peut être d'ajouter des
contraintes au C intermédiaire manipulé pour en obtenir un sous-langage. De
nombreux sous-ensembles ont été définis pour aller dans ce sens.

\subsubsection{Critères}

Les critères à évaluer sont les suivants :

\begin{itemize}
\item
  Forme (textuel / langage d'implem) : Quelle est la représentation du
  langage? Est-ce une bibliothèque (si oui, dans quel langage) a-t'il
  une forme textuelle (si oui, pour quels langages des \emph{parsers}
  existent ils).
\item
  Maturité : Le langage a-t'il ``fait ses preuves'' ? Est-il susceptible
  de changer ?
\item
  Tools
\item
  Support
\item
  Scope (analyse / compil) : pour quel type d'utilisation a-t'il été
  conçu ?
\item Expressivité : Peut-on compiler ``tout C'' ?
\item Orthogonalité
\item Typage
\item Sémantique existante
\end{itemize}

\subsubsection{Langages}

\begin{itemize}
\item
  LLVM\cite{llvm-pres} : un backend de compilateur développé par Apple.
\item
  Cmm (Haskell) : cf.
  \texttt{http://hackage.haskell.org/trac/ghc/wiki/Commentary/Compiler/CmmType}
\item
  Cmm (OCaml) : cf. \texttt{asmcomp/cmm.mli}
\item
  CIL\cite{NeculaCil} : cf. \texttt{www.cs.berkeley.edu/~necula/cil} puis
  \texttt{kerneis.github.com/cil} utilisé par Frama-C, Compcert.
\item
  Clight\cite{cfront} : Utilisé dans Compcert (front-end)
\item
  Cminor, utilisé dans Compcert (middle-end).
\item
  Cminusminus \cite{spjcmm} http://www.cminusminus.org/
\item
  Newspeak\cite{newspeak}, décrit dans la section~\ref{sec:npk}.
\end{itemize}

\begin{tabular}{| l || l | l |}
   \hline Nom           & Langage hôte    & Description
\\ \hline LLVM          & C++             & \cite{llvm-pres}
\\ \hline Cminusminus   & Texte           & \cite{spjcmm}
\\ \hline Cmm (Haskell) & Texte / Haskell &
\\ \hline Cmm (OCaml)   & OCaml           &
\\ \hline CIL           & OCaml           & \cite{NeculaCil}
\\ \hline Clight        & Coq             & \cite{cfront}
\\ \hline Cminor        & Coq             &
\\ \hline Newspeak      & Ocaml           & \cite{newspeak}
\\ \hline
\end{tabular}

\section{Newspeak}
\label{sec:npk}

\section{Chaîne de compilation}

\begin{figure}
  \input{fig/compil-pipeline.tex}
  \caption{Compilation depuis Newspeak}
  \label{fig:compil-npk}
\end{figure}

La compilation vers C est faite en trois étapes (figure~\ref{fig:compil-npk}) :
prétraitement du code source, compilation de C prétraité vers \newspeak{}, puis
compilation de \newspeak{} vers ce langage.

\subsection{Prétraitement}

\ctonewspeak{} travaillant uniquement sur du code prétraité (dans directives de
préprocesseur), la première étape consiste donc à faire passer le code par \cpp.

\subsection{Compilation (levée des ambigüités)}

Cette passe est réalisée par l'utilitaire \ctonewspeak{}. L'essentiel de la
compilation consiste à mettre à plat les définition de types, et à simplifier le
flôt de contrôle. C en effet propose de nombreuses constructions ambigües ou
redondantes.

Au contraire, \newspeak{} propose un nombre réduit de constructions. Rappelons
que le but de ce langage est de faciliter l'analyse statique : des constructions
orthogonales permettent donc d'éviter la duplication de règles sémantique, ou de
code lors de l'implémentation d'un analyseur.

Par exemple, plutôt que de fournir une boucle while, une boucle do/while et une
boucle for, \newspeak{} fournit une unique boucle \npkWhile{}. La sortie de
boucle est compilée vers un \npkGoto{}, qui est toujours un saut vers l'avant
(similaire à un "break" généralisé).

La sémantique de \newspeak{} et la traduction de C vers \newspeak{} sont
décrites dans \cite{newspeak}. En ce qui concerne l'élimination des sauts vers
l'arrière, on peut se référer à \cite{goto}.

\subsection{Annotations}

\newspeak{} a de nombreux avantages, mais pour une analyse par typage il est
trop bas niveau. Par exemple, dans le code suivant

\input{gen/struct-array.c.pyg.tex}

\subsection{Implantation de l'algorithme de typage}

Commençons par étudier le cas du lambda-calcul simplement typé
(figure~\ref{fig:stlc}).

\begin{figure}

\input{fig/lambda-simple.tex}

\caption{Lambda calcul simplement typé avec entiers, flottants et couples}
\label{fig:stlc}

\end{figure}

Prenons l'exemple de la fonction suivante\footnote{ On suppose que \texttt{plus}
est une fonction de l'environnement global qui a pour type $\tInt \rightarrow
\tInt \rightarrow \tInt$.} :

\[
f = λx.λy. \textrm{plus} (\textrm{plus} (\textrm{fst} x) (\textrm{snd} x)) y
\]

Informellement, on voit que puisque \texttt{fst} et \texttt{snd} sont appliqués
à \texttt{x}, ce doit être un tuple. En outre on additionne ces deux composantes
ensemble, donc elles doivent être de type \tInt (et le résultat aussi). Par le
même argument, \texttt{y} doit aussi être de type \tInt. En conclusion,
\texttt{x} est de type $\tInt \times \tInt$ et \texttt{y} de type $\tInt$, donc
f est de type $\tInt \times \tInt \rightarrow \tInt \rightarrow \tInt$.

Mais comment faire pour implanter cette analyse ? En fait le système de types de
la figure~\ref{fig:stlc} a une propriété particulièrement intéressante : chaque
forme syntaxique (variable, abstraction, etc) est en conclusion d'exactement une
règle de typage. Cela permet de toujours savoir quelle règle il faut appliquer
(c'est à rapprocher du fait qu'on peut déduire un analyseur syntaxique d'une
grammaire LL)

Partant du terme de conclusion ($f$), on peut donc en déduire un squelette
d'arbre d'inférence (figure~\ref{fig:inftree-rules})\footnote{Par souci de
clarté, les prémisses des applications de \textsc{(Var)} ne sont pas notées.}

\begin{figure} % {{{ Fig règles
\def\disptypeL#1{}
\def\disptypeR#1{}

\input{fig/inftree.tex}

\caption{Arbre d'inférence : règles à utiliser}
\label{fig:inftree-rules}
\end{figure} % }}}

\begin{figure} % {{{ Fig full tree
\def\disptypeL#1{:#1}
\def\disptypeR#1{:#1}

\input{fig/inftree.tex}

\caption{Arbre d'inférence complet}
\label{fig:inftree-full}
\end{figure} % }}}

Une fois à cette étape, on peut donner un nom à chaque type inconnu : $τ_1, τ_2,
\ldots$. L'utilisation qui en est faite permet de générer un ensemble de
contraintes d'unification. Par exemple, pour chaque application de la règle
\textsc{(App)} :

\[
\irule{App}{Γ⊢\ldots:τ_3 \\ Γ ⊢ \ldots : τ_1}{Γ ⊢ \ldots : τ_2}
\]

on doit déduire que $τ_3 = τ_1 \rightarrow τ_2$.

Ici $=$ est à prendre comme une contrainte d'égalité : partant d'un ensemble de
contraintes de la forme "type avec inconnue = type avec inconnue", on veut
obtenir une substitution "inconnue -> type concret".

Pour résoudre ces contraintes, on commence par les simplifier : si $τ_a
\rightarrow τ_b = τ_c \rightarrow τ_d$, alors $τ_a = τ_c$ et $τ_b = τ_d$. De
même si $τ_a \times τ_b = τ_c \times τ_d$. Au contraire, si $τ_a \rightarrow τ_b
= τ_c \times τ_d$, il est impossible d'unifier les types et il faut abandonner
l'inférence de types. D'autre cas sont impossibles, par exemple $\tInt = τ_1
\rightarrow τ_2$ ou $\tInt = \tFloat$.

Une fois ces simplifications réalisées, les contraintes restantes sont d'une des
formes suivantes :

\begin{itemize}
\item
  $τ_i = τ_i$. Il n'y a rien à faire, cette contrainte peut être supprimée.
\item
  $τ_i = τ_j$ avec $i \ne j$ : toutes les occurrences de $τ_j$ dans les autres
  contraintes peuvent être remplacées par $τ_i$. \todo{occurs check peut etre?}
\item
  $τ_i = x$ (ou $x = τ_i$) où $x$ est un type concret : idem.
\end{itemize}

\todo{C'est faux}

Une fois toutes les substitutions effectuées, on obtient un arbre de typage
correct (figure~\ref{fig:inftree-full}, donc un programme totalement inféré.

\begin{figure} % fig:unifpartage {{{

  \subfloat[][]{
  \label{fig:unifpartage:a}
  \begin{tikzpicture}
  \node               (var) {Var};
  \node[right of=var] (ref) {ref};
  \node[right of=ref, node distance=1.7cm] (u0) {Unknown 0};
  \node[below of=var] (ptr) {Ptr};
  \node[left of=var]  (x) {x :};
  \node[left of=ptr] (p) {p :};
  \draw[->] (x) -- (var);
  \draw[->] (p) -- (ptr);
  \draw[->] (ptr) -- (var);
  \draw[->] (var) -- (ref);
  \draw[->] (ref) -- (u0);
  \end{tikzpicture}
  }
  \subfloat[][]{
  \label{fig:unifpartage:b}
  \begin{tikzpicture}
  \node               (var) {Var};
  \node[right of=var] (ref) {ref};
  \node[right of=ref, node distance=1.7cm] (u0) {Instanciated};
  \node[right of=u0, node distance=1.7cm] (ii) {Int};
  \node[below of=var] (ptr) {Ptr};
  \node[left of=var]  (x) {x :};
  \node[left of=ptr] (p) {p :};
  \draw[->] (x) -- (var);
  \draw[->] (p) -- (ptr);
  \draw[->] (ptr) -- (var);
  \draw[->] (var) -- (ref);
  \draw[->] (ref) -- (u0);
  \draw[->] (u0) -- (ii);
  \end{tikzpicture}
  }
  \subfloat[][]{
  \label{fig:unifpartage:c}
  \begin{tikzpicture}
  \node               (var) {Int};
  \node[below of=var] (ptr) {Ptr};
  \node[left of=var]  (x) {x :};
  \node[left of=ptr] (p) {p :};
  \node[right of=ptr] (pi) {Int};
  \draw[->] (x) -- (var);
  \draw[->] (p) -- (ptr);
  \draw[->] (ptr) -- (pi);
  \end{tikzpicture}
  }

  \caption{Unification par partage}
  \label{fig:unifpartage}

\end{figure} % }}}

Plutôt que de modifier toutes les occurrences d'un type $τ_i$, on va affecter à
$τ_i$ la valeur du nouveau type.

L'implémentation de cet algorithme utilise le partage et les références
(figure~\ref{fig:unifpartage}).

D'abord \ref{fig:unifpartage:a}, ensuite \ref{fig:unifpartage:b}, et enfin
\ref{fig:unifpartage:c}.

\insertcode{lambda-types.ml}

\wip{}

\begin{center}\rule{3in}{0.4pt}\end{center}

Le programme C suivant :

\insertcode{ex-unif-c.c}

est compilé ainsi en Tyspeak :

\insertcode{ex-unif-tpk.ml}

