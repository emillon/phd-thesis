\section{Syntaxe}

Les différences principales avec C sont les suivantes :

\begin{itemize}
\item
  le flot de contrôle est simplifié : les seules constructions sont
  l'alternative, la boucle infinie et le saut en avant.
\item
  les expressions sont sans effets de bords. En particulier, leur
  évaluation peut être faite sans modifier l'environnement.
\item
  les opérateurs pour entiers et les flottants sont différenciées.
\item
  toutes les variables locales sont ``remontées'' en début de fonction.
\end{itemize}

\section{Sémantique}

La relation de transition est faite entre états de l'interpréteur, constitués
d'une part d'une continuation (section~\ref{sec:cont}, et d'autre part d'un
l'état $σ$ de la mémoire (section~\ref{sec:sigma}). Cette présentation est
proche de la sémantique de CMinor décrite dans\cite{cminorSL}

\begin{definition}[Relation de transition]
  La sémantique consiste en une relation de transition entre les états de
  l'interpréteur. Celle-ci est faite sous un environnement $Γ$ qui associe des
  adresses aux variables du programme.

  On note un tel pas $Γ ⊢ (k, σ) → (k', σ')$.
\end{definition}

\section{État mémoire}
\label{sec:sigma}

La sémantique permet de définir formellement comment s'exécute un programme. En
particulier, elle permet d'exprimer comment se comporte la mémoire d'un
interpréteur.

En pratique, la mémoire d'un ordinateur de type PC est similaire à un grand
tableau d'octets (cf. chapitre~\ref{cha:os}). On pourrait alors poser
$\textsc{Mem} = [0;2^{32} - 1] → [0;2^8 - 1]$ ; mais cette formalisation ne
fait aucune hypothèse sur la représentation en mémoire des données. En pratique,
les données sont regroupées en groupes de variables de tailles variées : si un
entier prend 4 octets, un tableau de 100 entiers prendra 400 octets.

Nous présentons deux représentations de la mémoire : une permettant de manipuler
des valeurs de haut niveau, comme des entiers, des flottants et des pointeurs.
La seconde quand à elle, consiste en des suites d'octets. Cette distinction
permet de distinguer les opérations entre valeurs, et les opérations de
stockage et de chargement.

\subsection{Valeurs}

\gramlr{Valeurs}{
\begin{align*}
v  \gramisa  & n           & \textrm{Entier}
\\ \gramor   & f           & \textrm{Flottant}
\\ \gramor   & \cNil       & \textrm{Pointeur nul}
\\ \gramor   & a           & \textrm{Pointeur sur l'adresse $a$}
\\ \gramor   & \&f         & \textrm{Pointeur sur la fonction $f$}
\\ \gramor   & \top        & \textrm{Valeur non initialisée}
\end{align*}
}


On note l'ensemble de ces valeurs \sVal.

\subsection{Stockage et chargement mémoire}

Le stockage consiste en une fonction de conversion $\textrm{Inj} ∈ \sVal →
\sByte^*$, où \sByte* désigne l'ensemble des mots (suites finies) de \sByte.

Le chargement est une fonction $\textrm{Proj} ∈ \sByte^* → \powerset{\sVal}$.

\begin{definition}[État mémoire]
L'interpréteur possède une mémoire, indexée par un ensemble d'adresses noté
\textsc{Addr}. Un état mémoire $σ$ est une fonction partielle de \textsc{Addr}
vers \textsc{Val}.
\end{definition}

\todo{Il faut une opération genre fromBytes}

\begin{definition}[Fonction de transition]
La sémantique concrète que nous définissons ici est constituée de jugements
logiques. Le jugement principal est une relation de transition $\rightarrow$
entre états de l'interpréteur : il sera donc noté $Γ ⊢ (l, σ) \rightarrow (l', σ')$.
\end{definition}

\section{Continuations}
\label{sec:cont}

Pour représenter le flot de contrôle dans la sémantique, plusieurs choix sont
possibles. L'un est d'établir un graphe de flot de contrôle explicite et de
raisonner en termes de points de contrôle. Celui que nous retenons consiste à
voir l'exécution du programme en terme de continuations. Une continuation
capture ``ce qu'il reste à faire'' pour terminer l'exécution d'un programme.

Dans le cas le plus simple, il n'y a rien à faire (si le bloc d'initialisation
est vide par exemple ; ce sera aussi le cas de base de la plupart des autres
continuations). Cette continuation sera notée \kPass.

Il est aussi possible d'avoir à exécuter une instruction avant de passer à une
autre continuation. Cette séquence sera notée \kSeq{i}{k} (ou en notation
infixe, $i \cdot k$, avec la convention $i_1 \cdot i_2 \cdot k = i_1 \cdot (i_2
\cdot k) $).

Le flot de contrôle intraprocédural est uniquement réduit au saut en avant : on
peut nommer un bloc, et sauter à la sortie de celui-ci. Il faut donc pouvoir
capturer la continuation qui correspond à la sortie de ce bloc. Ce sera noté
$\kBlock{lbl}{k}$. Le saut en lui-même est une simple instruction, notée
$\npkGoto{lbl}$.

Enfin, le flot de contrôle interprocédural est similaire : l'appel d'une
fonction $f$ avec les arguments $\vec{v}$ et recevant l'adresse de retour dans
$a$ est noté $\kCall{f}{\vec{v}}{a}{k}$ ; et le retour d'une fonction est
\kRet{v}.

\gramlr{Continuations}{
\begin{align*}
k  \gramisa & \kPass                   & \textrm{Terminaison}
\\ \gramor  & \kSeq{i}{k}              & \textrm{Séquence}
\\ \gramor  & \kBlock{lbl}{k}          & \textrm{Sortie de bloc nommé}
\\ \gramor  & \kCall{f}{\vec{v}}{a}{k} & \textrm{Appel de fonction}
\\ \gramor  & \kRet{v}                 & \textrm{Retour de fonction}
\end{align*}
}

Parmi celles-ci, il y a deux cas de base (de terminaison) : \kPass et
\phx{\kRet}. Le premier servira à terminer le bloc d'initialisation et le
second les corps de fonction.

\section{Interprétation}

\begin{definition}[État initial]

  Pour un programme $P = (\vec{f},\vec{v},b)$, on définit sa continuation
  initiale comme étant celle qui exécute son bloc d'initialisation : $k_0 (P) =
  \kSeq{b}{\kPass}$.

  L'environnement initial $Γ_0(P)$ associe à chaque globale à une certaine
  adresse.

  Enfin, l'état mémoire initial laisse toutes les variables globales non
  initialisées :

  \[ σ_0(P) = \{ v_i ↦ \top \} \]

\end{definition}

\begin{definition}[Exécution d'un programme]

  L'exécution d'un programme $P$ résulte en un état mémoire final $σ_f$ si :

  \[ Γ_0(P) ⊢ (k_0(P), σ_0(P)) → (\kPass, σ_f) \]

\end{definition}

Dans la suite on définit la sémantique des left-values et des expressions. À cause des
opérateurs de déréférencement, il est nécessaire de les définir de manière
mutuellement récursive.

\section{Sémantique des left-values}

La mémoire est organisée en adresses, mais pourtant dans le programme cette
notion n'est pas directement visible. Les accès sont réalisés à travers des
"left values". Dans le langage C, elles correspondent aux constructions qui
peuvent se retrouver à gauche du signe ``='' dans une affectation.

\begin{definition}[Adresse effective]
  Sous un environnement $Γ$ et un état mémoire $σ$, une left-value peut
  correspondre à une adresse $a$. On dit que $a$ est l'adresse effective de
  $lv$, ce que l'on notera :

  \[ Γ, σ ⊢ lv ↝ a \]
\end{definition}

L'environnement $Γ$ contient les adresses des variables du programme. Pour une
left-value qui est une variable, le résultat est donc directement présent dans
$Γ$:

\begin{mathpar}
\irule{Eval-Lv-Var}{
  (v, a) ∈ Γ
}{
  Γ, σ ⊢ v ↝ a
}
\end{mathpar}

Dans le cas du déréférencement, il faut évaluer la valeur du pointeur (cette
opération est détaillée dans la section~\ref{sec:sem-expr}). Si celle ci est une
adresse, c'est l'adresse effective du déréférencement.

\begin{mathpar}
\irule{Eval-Lv-Deref}{
  Γ, σ ⊢ e ⇒ a
}{
  Γ, σ ⊢ *e ↝ a
}
\end{mathpar}

\begin{mathpar}
\irule{Eval-Lv-Field}{
  Γ, σ ⊢ lv ↝ a
}{
  Γ, σ ⊢ lv.f ↝ a + f
}
\and
\irule{Eval-Lv-Array}{
  Γ, σ ⊢ lv ↝ a \\
  Γ, σ ⊢ e ⇒ n
}{
  Γ, σ ⊢ lv[e] ↝ a + n
}
\end{mathpar}

\section{Sémantique des expressions}
\label{sec:sem-expr}

Les expressions sont les constructions syntaxiques de base du langage. Étant
donné un environnement et un état mémoire, on peut leur associer une valeur.

Par exemple, dans l'environnement qui à la variable $x$ associe l'adresse $a$ et
dans l'état mémoire qui à l'adresse $a$ associe la valeur $2$, l'expression $x +
3$ s'évalue en $5$.

\begin{definition}[Évaluation d'une expression]
  Sous un environnement $Γ$ et un état mémoire $σ$, une expression $e$ peut
  produire une valeur $v$. On notera :

  \[ Γ, σ ⊢ e ⇒ v \]
\end{definition}

Dans le cas où l'expression est une constante, c'est directement le résultat.

\begin{mathpar}
\irule{Eval-Cst}{
}{
  Γ, σ ⊢ c ⇒ c
}
\end{mathpar}

Si l'expression est une left-value, on établit à quelle adresse elle correspond
et on récupère dans l'état mémoire à quelle valeur celle-ci correspond.

\begin{mathpar}
\irule{Eval-Lv}{
  Γ, σ ⊢ lv ↝ a \\
  (a, v) ∈ σ
}{
  Γ, σ ⊢ lv ⇒ v
}
\end{mathpar}

En ce qui concerne les opérations (unaires ou binaires), on commence par évaluer
les opérandes. Le résultat est l'opération "concrète" sur les valeurs, notée
$\widehat{\opsymb}$. Par exemple, pour la construction syntaxique $+$, on
utilise l'addition sur les valeurs $\widehat{+}$ (c'est-à-dire l'addition
usuelle).

\begin{mathpar}
\irule{Eval-Unop}{
  Γ, σ ⊢ e ⇒ v
}{
  Γ, σ ⊢ \opsymb~e ⇒ \widehat{\opsymb}~v
}
\and
\irule{Eval-Binop}{
  Γ, σ ⊢ e_1 ⇒ v_1 \\
  Γ, σ ⊢ e_2 ⇒ v_2
}{
  Γ, σ ⊢ e_1~\opsymb~e_2 ⇒ v_1~\widehat{\opsymb}~v_2
}
\end{mathpar}

Enfin, les adresses sont aussi des valeurs. Le cas des pointeurs sur fonction
est direct puisque toutes les fonctions sont globales ; pour le cas des
pointeurs sur données on commence par déterminer l'adresse de l'objet pointé
depuis l'état mémoire.

\begin{mathpar}
\irule{Eval-AddrOfFun}{
}{
  Γ, σ ⊢ \&f ⇒ \&f
}
\and
\irule{Eval-AddrOf}{
  Γ, σ ⊢ lv ↝ a
}{
  Γ, σ ⊢ \&lv ⇒ a
}
\end{mathpar}

\section{Sémantique des instructions}

On définit ici la relation de transition $→$. Selon la forme de la continuation,
deux grandes familles sont à distinguer : les instructions classiques et celles
qui manipulent le flot de contrôle.

Si $i$ est une séquence, on la décompose. De même, les blocs vides peuvent être
sautés :

\begin{mathpar}
  \iaxiom{Instr-Seq}
    {Γ ⊢ ((i_1 ; i_2) \cdot k, σ) → (i_1 \cdot (i_2 \cdot k), σ)}
  \and
  \iaxiom{Instr-Skip}
    {Γ ⊢ (ε \cdot k, σ) → (k, σ)}
\end{mathpar}

Si $i$ est une affectation, on évalue l'expression et on modifie l'état $σ$ en
conséquence.

\begin{mathpar}
  \irule{Instr-Assign}{
    Γ, σ ⊢ lv ↝ a \\
    Γ, σ ⊢ e ⇒ v
  }{
    Γ ⊢ (lv \leftarrow e \cdot k, σ) \rightarrow (k, σ [ a ↦ v ])
  }
\end{mathpar}

\section{Flot de contrôle intraprocédural}

Réaliser une boucle infinie revient à d'abord exécuter le bloc puis à exécuter à
nouveau la boucle :

\begin{mathpar}
\iaxiom{Instr-While}
  { Γ ⊢ (\npkWhile{b} \cdot k, σ) → (b . \npkWhile{b} \cdot k, σ) }
\end{mathpar}

La capture d'une sortie de bloc nommé consiste à remplacer la continuation en
cours par une continuation \phxx{\kBlock}.

\begin{mathpar}
\iaxiom{Instr-DoWith}
  { Γ ⊢ ((\npkDoWith{b}{lbl}) \cdot k, σ) → ( b \cdot \kBlock{lbl}{k}) }
\end{mathpar}

Pour le saut, deux cas sont à considérer. Dans le premier cas, on sort du bloc
le plus interne ; dans l'autre, on sort d'un bloc qui n'est pas final.

\begin{mathpar}
\iaxiom{Instr-Goto-Int}
  { Γ ⊢ ( \npkGoto{lbl} \cdot … \cdot \kBlock{lbl}{k}, σ) → (k, σ) }
\and
\irule{Instr-Goto-Ext}
{ lbl ≠ lbl' }
{ Γ ⊢ ( \npkGoto{lbl} \cdot … \cdot \kBlock{lbl'}{k}, σ) → (\npkGoto{lbl} \cdot k, σ) }
\end{mathpar}

Pour la conditionnelle, on évalue la condition. Si elle s'évalue en un entier
non nul, la suite est le bloc ``vrai'', sinon c'est le bloc ``faux''.

\begin{mathpar}
\irule{Instr-If-True}
  { Γ, σ ⊢ e ⇒ n \\
    n ≠ 0
  }
  {
    Γ ⊢ (\npkIf{e}{i_t}{i_f} \cdot k, σ) → (i_t \cdot k, σ)
  }
\and
\irule{Instr-If-False}
  { Γ, σ ⊢ e ⇒ 0
  }
  {
    Γ ⊢ (\npkIf{e}{i_t}{i_f} \cdot k, σ) → (i_f \cdot k, σ)
  }
\end{mathpar}

\section{Appel de fonctions}

Pour $f = (\vec{v}, b)$, on note $k_0(f) = b \cdot \kPass$ et $\vec{params}(f) =
\vec{v}$.

Pour une instruction \npkReturn{e}, on évalue l'expression en une valeur $v$ et
on remplace la continuation courante par $\kRet{v}$.

\begin{mathpar}
  \irule{Instr-Return}
    { Γ, σ ⊢ e ⇒ v }
    { Γ ⊢ (\npkReturn{e} \cdot k, σ) → (\kRet{v}, σ)
    }
\end{mathpar}

L'appel de fonction se fait en deux étapes : tout d'abord, quand on rencontre un
appel de fonction, on évalue les arguments et la left-value de retour et on
construit une continuation $\kCall{f}{\vec{v}}{a}{k}$, qui remplace la continuation
courante.

\begin{mathpar}
  \irule{Instr-Fcall}
    { Γ, σ ⊢ lv ↝ a
   \\ Γ, σ ⊢ \vec{e} ⇒ \vec{v}
    }
    { Γ ⊢ (lv ← f(\vec{e}) \cdot k, σ) → (\kCall{f}{\vec{v}}{a}{k}, σ) }
\end{mathpar}

Pour évaluer celle-ci, on évalue le corps de la fonction dans un environnement
enrichi des paramètres de la fonction, jusqu'à ce que sa continuation soit
\phx{\kRet}.

\begin{mathpar}
  \irule{Instr-Kcall}
    { Γ' = ? \\
      σ' = σ + \{ \vec{params}(f) := \vec{v} \} \\
      Γ' ⊢ (k_{0}(f), σ') → (\kRet{v_r}, σ'')
    }
    { Γ ⊢ (\kCall{f}{\vec{v}}{a}{k}, σ) → (k, σ'' [ a := v_r ]) }
\end{mathpar}

\section{Programmes bien formés}

La syntaxe décrite ci-dessus ne permet pas de donner du sens à tous les
programmes : par exemple les programmes suivants ne peut pas être évalués.

\begin{figure} % Fig Progs mal formés{{{
    \centering

\begin{SubFloat}{\label{fig:progmf-a}Saut vers une étiquette inexistante}
\begin{minipage}[b]{0.4\linewidth}
\begin{Verbatim}
{
  Goto a
}
\end{Verbatim}
\end{minipage}
\end{SubFloat}
\begin{SubFloat}{\label{fig:progmf-b}Saut vers une étiquette non visible}
\begin{minipage}[b]{0.4\linewidth}
\begin{Verbatim}
{
  Do {
    Goto b
  } With a:
  Do {
  } With b:
}
\end{Verbatim}
\end{minipage}
\end{SubFloat}

\vspace{1cm}

\begin{SubFloat}{\label{fig:progmf-c}Saut interprocédural}
\begin{minipage}[b]{0.4\linewidth}
\begin{Verbatim}
f(x) {
  Goto a
}

{
  Do {
    f(1)
  } With a:
}
\end{Verbatim}
\end{minipage}
\end{SubFloat}
\begin{SubFloat}{\label{fig:progmf-d}Retour dans bloc d'initialisation}
\begin{minipage}[b]{0.4\linewidth}
\begin{Verbatim}
{
  Return 0
}
\end{Verbatim}
\end{minipage}
\end{SubFloat}

  \caption{Programmes mal formés}
  \label{fig:progmf}
\end{figure} % }}}

Dans le cas de la figure~\ref{fig:progmf-a} la continuation est $\npkGoto{a}
\cdot \kPass$, et aucune règle d'évaluation ne permet de la réduire : les seules
possibilités pour une continuation de la forme $\npkGoto{l} \cdot k$ sont
lorsque $k = … \cdot … \cdot \kBlock{l'}{k'}$. Syntaxiquement, c'est un problème
de visibilité : au niveau d'un $\npkGoto{l}$, l'étiquette $l$ doit être visible.

Ce problème existe aussi dans la figure~\ref{fig:progmf-b} : l'étiquette $b$
existe, mais n'est pas visible au moment de $\npkGoto{b}$ (où seule $a$ l'est).

La visibilité concerne les blocs, mais pas les fonctions. Cela implique qu'on ne
peut pas sauter entre plusieurs fonctions, comme dans la
figure~\ref{fig:progmf-c}.

La figure~\ref{fig:progmf-d} illustre un autre problème : le bloc
d'initialisation ne doit pas contenir d'instruction \phx{\npkReturn}. En effet,
dans ce cas la continuation devient $\kRet{0}$ et ne permet pas de terminer
l'évaluation du programme en obtenant une continuation $\kPass$.

Un programme est bien formé si les trois conditions suivantes sont
présentes:

\begin{itemize}
\item
  chacune des fonctions du programme est bien formée.
\item
  le bloc d'initialisation est bien formé
\item
  ce dernier ne contient pas d'instruction
  \phx{\npkReturn}.
\end{itemize}

En outre, une fonction est bien formée si son corps l'est.

\begin{mathpar}
\irule{WF-Prog}
  { \WF{\vec{f}} \\
    \WF{b} \\
    \NORET{b}
  }
  {\WF{(\vec{f}, \vec{v}, b)}}
\and
\irule{WF-Func}{ \WF{body(f)} }{ \WF{f} }
\end{mathpar}

La notion de bloc bien formé repose sur la portée des étiquettes : par exemple,
une instruction \phx{\npkGoto} est formée si son étiquette est dans l'ensemble
des étiquettes visibles. On note $L ‣ b$ si $b$ est bien formé avec un ensemble
d'étiquettes visibles $L$.

Ainsi, un bloc est bien formé s'il est bien formé avec aucune étiquette visible.

\begin{mathpar}
\irule{WF-Blk}{ ∅ ‣ b }{ \WF{b} }
\end{mathpar}

La structure en séquence ne modifie pas le fait d'être bien formé :
l'instruction vide est toujours bien formée, et pour une séquence, il est
équivalent que l'instruction de tête et la suite d'instructions de queue soient
bien formées sous le même ensemble d'étiquettes.

\begin{mathpar}
     \iaxiom{WF-Pass}{ L ‣ ε }
\and \irule{WF-Seq}{ L ‣ i \\ L ‣ b }{ L ‣ i;b }
\end{mathpar}

Les instructions simples (ne contenant pas d'étiquette ou d'autre bloc) sont
toujours bien formées.

\begin{mathpar}
     \iaxiom{WF-Set}{ L ‣ lv \leftarrow e}
\and \iaxiom{WF-Fcall}{ L ‣ lv \leftarrow funexp (args)}
\and \iaxiom{WF-Return}{ L ‣ \npkReturn{e}}
\end{mathpar}

Les instructions contenant d'autres blocs sont bien formées lorsque leurs
sous-blocs sont bien formés.

\begin{mathpar}
     \irule{WF-While}{L ‣ b}{L ‣ \npkWhile{b}}
\and \irule{WF-If}{L ‣ b_1 \\ L ‣ b_2}{L ‣ \npkIf{e}{b_1}{b_2}}
\end{mathpar}

Un bloc \phxx{\npkDoWith} est bien formé si son bloc interne est bien formé;
mais sous un ensemble d'étiquettes étendu du nouveau label, puisque celui-ci y
est visible.

\begin{mathpar}
\irule{WF-DoWith}{L,lbl ‣ b}{L ‣ \npkDoWith{b}{lbl}}
\end{mathpar}

Enfin, un \phx{\npkGoto} est bien formé sous un ensemble d'étiquettes contenant
sa destination.

\begin{mathpar}
\irule{WF-Goto}{lbl ∈ L}{L ‣ \npkGoto{lbl}}
\end{mathpar}

La définition de ce qu'est un bloc $b$ sans instruction \phx{\npkReturn} (noté
$\NORET{b}$) est plus simple : c'est la définition récursive des blocs, en
omettant le cas de base \phx{\npkReturn}.

\begin{mathpar}
     \iaxiom{NR-Pass}{ \NORET{ε} }
\and \irule{NR-Seq}{\NORET{i} \\ \NORET{b}}{ \NORET{i;b} }
\and \iaxiom{NR-Set}{ \NORET{lv \leftarrow e}}
\and \iaxiom{NR-Fcall}{lv \leftarrow funexp (args)}
\and \irule{NR-While}{\NORET{b}}{\npkWhile{b}}
\and \irule{NR-If}{ \NORET{b_t} \\ \NORET{b_f} }{\npkIf{e}{b_t}{b_f}}
\and \irule{NR-DoWith}{ \NORET{b} }{\npkDoWith{b}{lbl}}
\and \iaxiom{NR-Goto}{\npkGoto{lbl}}
\end{mathpar}
