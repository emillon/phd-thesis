\section{État de l'art}

\begin{itemize}
\item IA :

  \begin{itemize}
  \item produit réduit
  \item polyspace?
  \item APRON?
  \item Frama-C ?
  \end{itemize}

\item difficultés : récursion

\item
  hoare : quand est-ce que le compile time suffit ? et le runtime nécessaire ?
\item
  types : citer H98\cite{haskell98}, perl \cite{perlCamelBook}, DAOC\cite{DAOC}
  \& RWH\cite{rwh}?
\item proof assistants
  \begin{itemize}
  \item Dependent types
  \item proof $:$ theorem $::$ type $:$ term
  \item Coq
  \item Agda, termination checker
  \item proof irrelevance
  \item Theorems for Free\cite{theoremsforfree}
  \end{itemize}
% TODO [E] ça manque effectivement

\item
  Analyse de flot :
Ce que nous voulons vérifier peut être vue comme une propriété de flot. Un tour
d'horizon des problèmes et techniques existantes peut être trouvé
dans~\cite{sm-jsac03}.

\item Divers : Taint sequences \cite{mdv10},
\item Régions \cite{jfp92} \cite{popl94} \cite{ToTa1993}

% TODO [E] idem
\end{itemize}


L'analyse de taintage consiste à ajouter des étiquettes au données décrivant
leur provenance, de manière à ce que chaque accès dangereux soit vérifié à
l'exécution. Cela se marie bien avec les langages typés dynamiquement, comme le
montre l'exemple célèbre du mode ``souillé'' (\emph{tainted}) de
Perl~\cite{perlCamelBook}. Il est aussi possible, mais plus délicat, d'appliquer
cette technique à des langages compilés~\cite{clause-etal-issta07,oakland10}.
% TODO [E]: à préciser

% ----

Les systèmes de types les plus simples expriment des
contrats esssentiellement liés à la sûreté d'exécution, pour ne pas utiliser des
valeurs de types incompatibles entre eux. Mais il est possible d'étendre le
langage avec des annotations plus riches : par exemple en vérifiant statiquement
que des listes ne sont pas vides\cite{lightweight-static-capabilities}, ou dans
le domaine de la sécurité, d'empêcher des fuites d'information~\cite{LZ06a}.

% ---

% TODO à mettre où?

\begin{itemize}
\item
Les pointeurs sur fonction rendent floue la limite qui est habituellement
présente entre instructions et données. En leur présence il est impossible de
faire une analyse de flot de contrôle indépendante du flot de données. Pour
pouvoir les traiter, il faut que le domaine abstrait en question soit assez
précis pour qu'un pointeur abstrait se concrétise en un ensemble réduit de
fonctions. Dans le cas où le domaine ne peut pas borner l'ensemble des fonctions
possibles et renvoie $\top$, l'analyse ne peut pas continuer.

\item
L'allocation dynamique de données, présente dans le langage C par le biais des
fonctions \texttt{malloc} et \texttt{free}, modifie le modèle mémoire
nécessaire. Sans celle-ci, l'ensemble des zones mémoire possibles peut être
décrit statiquement : ce sont les noms de variable. Ce qu'introduit
\texttt{malloc} au langage, c'est une zone mémoire qui n'a pas de nom, et sur
laquelle on n'a qu'un pointeur.

% TODO, bof + expand

\item
Le transtypage (\emph{casts}) entre entiers et pointeurs est particulièrement
délicat à traiter. Dans les modèles abstraits, les pointeurs sur données ou sur
fonctions n'ont pas de représentation numérique, seulement une représentation
symbolique. Même dans l'exécution concrète, la représentation numérique d'un
pointeur est lié à de nombreux choix faits par l'environnement d'exécution
(comme la randomisation de l'espace d'adressage) qui ne peuvent pas facilement
être modélisés.

\item
Les nombres flottants (types \texttt{float}, \texttt{double} et \texttt{long
double}) ont une sémantique particulière, et il n'est pas correct d'approcher
leur sémantique par une sémantique dans $ℝ$. Afin d'être correct, il faut
établir des domaines spécifiques au flottant, comme~\cite{floatpoly}. Un tour
d'horizon des difficultés liées aux flottants est effectué
dans~\cite{floatpitfalls}.

\end{itemize}

\paragraph{Qualificateurs de types}

Dans le cas particulier des vulnérabilités liées à une mauvaise utilisation de
la mémoire, les développeurs du noyau Linux ont ajouté un système d'annotations
au code source. Un pointeur peut être décoré d'une annotation
\texttt{\_\_kernel} ou \texttt{\_\_user} selon s'il est sûr ou pas. Celle-ci
sont ignorées par le compilateur, mais un outil d'analyse statique ad-hoc nommé
Sparse~\link{sparse}~\cite{TorvaldsSparse} % TODO citer un seul peut être
utilisé pour détecter les cas les plus simples d'erreurs. Il demande aussi au
programmeur d'ajouter beaucoup d'annotations dans le programme. % TODO
quantifier

Ce système d'annotations sur les types a été formalisé sous le nom de
\emph{qualificateurs de types} : chaque type peut être décoré d'un ensemble de
qualificateurs (à la manière de \texttt{const}), et des règles de typage
permettent d'établir des propriétés sur le programme. Ces analyses ont été
implantée dans l'outil CQual~\cite{toplas-quals}. Ce système peut servir à
inférer les annotations \texttt{const}~\cite{pldi99}, à l'analyse de souillure
pour les chaîne de format~\cite{usenix01} % TODO citer Newsham sur le format ?
et des propriétés dépendantes du flot de contrôle, comme des invariants sur les
verrous~\cite{pldi02}, à rapprocher du concept de \emph{typestates}
~\cite{tse12-typestate}. Il a également été appliqué à la classe de
vulnérabilités sur les pointeurs utilisateurs dont il est ici
l'objet~\cite{cquk-usenix04}. Puisqu'elle consiste à ajouter un qualificateur à
chaque étage de type, cette approche est plus générique mais plus complexe que
la nôtre. % TODO bof

% TODO [E] préciser pourquoi

\section{Évaluateur}

\begin{itemize}
\item substitutions dans les ctx : éditer $C_l$ et $C_i$
  (en fait, séparer selon le truc substitué (2è arg), pas le premier)
\item cas d'erreur si on accède à un index d'une struct ou vice versa?
\item Exp-AddrOf sur toutes les lv
\item C ::= \&C
\item changer les para de présentation des règles
\item widehats sur les constantes ?
\item liste d'assos $→$ fonction
\item définir les opérations d'ajout/remplacement sur les états mémoire
\item interdire d'avoir plusieurs variables qui ont le même nom dans un cadre
\item return implicite en fin de fct
\item clarifier quand il faut un $\mm{\cdot}{\cdot}{\cdot}{\cdot}$
             et quand il faut un $\mmstar{\cdot}{\cdot}{\cdot}{\cdot}$
\item "et" et "ou" lazy
\item dans les lentilles, L désigne à la fois celle des champs et celle des
listes d'asso
\end{itemize}

Limitations :

\begin{itemize}
\item (ou feature) variables non initialisées
\item tableaux de taille dynamique ?
\item structures récursives et corécursives
\item figures gramdef : singulier ou pluriel?
\end{itemize}

\subsection*{Extrait PLAS}

We present \langname, a memory-safe imperative programming language. Let us go
through its major features.

\paragraph{Scalar data:} there are four types of scalars: integers, floats,
pointers and a special ``unit'' value. Integers are 32 bit wide signed integers,
akin to the \texttt{int32\_t} data type in C, but this size is arbitrary. Floats
are 32 bit wide floating point numbers with their usual semantics,
Pointers are used to reference any modifiable piece of data, as embodied by the
concept of \emph{left-values} described below. Finally, the special unit value,
written \eUnit is the one that is returned by procedures that do not return a
useful value. It is similar to the \texttt{unit} type of some functional
languages. A particular $\eTaint{e}$ construct allows us to construct
expressions annotated as coming from userspace, emulating a system call, and two
operators $\uGet{\cdot}{\cdot}$ and $\uPut{\cdot}{\cdot}$ provide safe copy from
and to userspace.

{ \small
\begin{align*}
  \gramdefshort{Expressions}{e}
                 { c               }{ Constant }
                 { lv              }{ Left-value }
                 { \opun~e         }{ Unary operation }
                 { e~\opbin~e      }{ Binary operation }
                 { \&~lv           }{ Pointer }
                 { lv ← e          }{ Assignment }
                 { \{ l_1 : e_1
                    ; …
                    ; l_n : e_n \} }{ Structure }
                 { [ e_1 ;…; e_n ] }{ Array }
                 { \eFun{x_1, …, x_n}{i} }{ Function }
                 { e (e_1, …, e_n) }{ Function call }
                 { \eTaint{e}      }{ Tainted value }
                 { \uGet{lv}{e}    }{ Load from userspace }
                 { \uPut{e}{e}     }{ Store to userspace }
                 {END} \\
  \\
  \gramdefshort{Constants}{c}
               { n      }{ Integer }
               { d      }{ Float }
               { \eNull }{ Null pointer }
               { \eUnit }{ Unit value }
               {END}
\end{align*} }%


\paragraph{Composite data:} there are two kinds of composite data: arrays and
structures. Arrays are homogeneous pieces of memory with a fixed, statically
known size. Elements within an array can be accessed with an integer
index.
In the case of an array with $n$ elements,
the first one is accessed with the index $0$,
and the last one with $n-1$.
Trying to access to an element
with any other index results in a run-time error.
Arrays are written $[ e_1; …; e_n ]$ with $n>0$. Unlike in C, there is no
particular relation between arrays and pointers: arrays are plain values that
can be passed around.

The other kind of composite data is structures, that are an heterogeneous
collection of variables of a fixed size. Elements are accessed with a
\emph{label} $l_S$, that is always statically known (labels are not first-class
elements of the language). The subscript $S$ index is placed here by our
translator to guide type inference, and is ignored by the evaluator. Structures
are written $\{ l_1 : e_1 ; … ; l_n : e_n \}$ with $n>0$.

\paragraph{Memory} is organised in variables, that hold scalar or composite
data. It is split between a stack of local variables, and a set of global
variables. Local variables are structured in a list of stack frames that are
used to hold information for each function call. Global variables are on the
other hand an unstructured set accessible anywhere in the program. We suppose
that inside every function, all locals have a distinct name ; same goes for
globals. Local variables from two different function can have the same name.

\paragraph{Left-values:} Inside expressions, it is possible to directly access
visible variables, that is the ones that are part of the most recent stack
frame, and global ones. It is also possible to manipulate other parts of the
memory by the means of a pointer. Pointers hold enough information
to address in a non ambiguous manner any part of the memory.%
{\small \begin{align*}
  \gramdefshort{Left-values}{lv}
                  { x      }{ Variable }
                  { \hspace{-2pt}*lv    }{ Dereference }
                  { lv.l_S }{ Field access }
                  { lv[e]  }{ Indexed access }
                  {END}
\end{align*}}%
\paragraph{Operators} are used to combine expressions together. We support C's
operators on scalar data. To help the type system, we distinguish between
integer operations and floating point operations by writing the latter with an
extra dot: for example $3 + 2 = 5$ and $3.14~+_.~2.72 = 5.86$. Equality (and
difference) tests can be done on scalar data as well as on composite data. In
that case, it is done recursively on their members. Pointers are equal if they
describe the same path in memory. Pointer arithmetic is possible by the means of
operators $+_p$ and $-_p$, that move a pointer inside an array (if it used on
another type of pointer, it results in a run-rime error $\serr{ptr}$).

\paragraph{Functions} are first-class expressions that can be assigned to
variables that can then be called. However, unlike in some other programming
languages, they are not lexical closures, meaning that no capture of variables
from enclosing scopes happen at the site of a function declaration.

This is a compromise between C where functions can only be global, and
functional languages where it is necessary to build closures containing (pointers
to) captured variables at each function call. This also eliminates the need for
special-cased ``function pointers''.

Each function call creates a stack frame to hold room for the function's
parameters and local variables. Upon return, the most recent frame is destroyed.
A specificity of our system is that at this moment, we also clear references
that are about to become invalid. More precisely, we turn to \eNull every
pointer that refer to the latest stack frame. Using this technique, we can avoid
so-called \emph{dangling} pointers.

Note that this is a dynamic step and requires a full memory scan, which is very
inefficient. This is done only for soundness reasons ; as discussed in
Section~\ref{sec:limit}, if a preliminary analysis proves that this is
unnecessary we can skip this step.

\paragraph{Instructions} inside functions includes the empty instruction,
sequence, evaluation of an expression (including assignment), or variable
declation. Control flow is restricted to alternative (\textsc{If}) and loops
(\textsc{While}). The \textsc{Return} construct also exits early from the
current function.
%%%%%
{ \small \begin{align*}
  \gramdefshort{Instructions}{i}
                 { \iPass          }{Empty instruction}
                 { i_1;i_2         }{Sequence}
                 { e               }{Expression}
                 { \iDecl{x}{e}{i} }{Declaration}
                 { \iIf{e}{i}{i}   }{Alternative}
                 { \iWhile{e}{i}   }{Loop}
                 { \iReturn{e}     }{Function return}
                 {END}
\end{align*}}

\paragraph{A program} is a sequence of top-level sentences, of the form of
global declarations or expressions. A declaration creates a global variable
that is accessible everywhere after in the whole program.
On the other hand, a plain expression is only evaluated for its side-effects
\footnote{
  There is no implicit entry point such as a $\mathrm{main}()$ function, so
  it is necessary to manually insert a call it.
}
.%
{ \small
\begin{align*}
  \gramdefshort{Toplevel sentences}{s}
                 { x = e }{Global variable}
                 { e     }{Expression evaluation}
                 {END}
  \\
  P \gramisa & (s_1, …, s_n) & {\textrm{\larger \textbf{Program}}}
\end{align*}}%
\begin{figure*}

  \centering
  {\small {

  \begin{minipage}{0.29\textwidth}
  \begin{align*}
  \gramdefshort{Values}{v}
      { \widehat{c}     }{Constant}
      { \widehat{f}     }{Function}
      { \widehat{\&}~φ  }{Reference}
      { \widehat{
         \{ l_i : v_i;… \}
       }                }{Structure}
      { \widehat{
        [ v_i ;… ]
        }               }{Array}
      { Ω               }{Error}
      {END}
  \\
  \gramdefshort{Paths}{φ}
     { a    }{Address}
     { *φ   }{Dereference}
     { φ.l  }{Field}
     { φ[n] }{Index}
     { \vTainted{φ} }{Tainted value}
     {END}
  \end{align*}
  \end{minipage}
  \begin{minipage}{0.4\textwidth}
  \begin{align*}
  \gramdefshort{Stack}{s}
    { [~] }{Empty stack}
    { \{ x_i ↦v_i; …\} :: s}{Extra frame}{END}
  \\
  \gramheadershort{Memory}{m} \\
    & (s, & \textrm{Stack,} \\
    & \{ x_1 ↦v_1; … \}) & \textrm{globals} \\
  \\
  \gramdefshort{Addresses}{a}
     { (n, x) }{Local variable}
     { (x)    }{Global variable}
     {END}
  \end{align*}
  \end{minipage}
  \begin{minipage}{0.3\textwidth}
  \begin{align*}
  \gramdefshort{Errors}{Ω}
    { \serr{array} }{Buffer overflow}
    { \serr{ptr}   }{Invalid dereference}
    { \serr{div}   }{Division by zero}
    { \serr{field} }{Bad field}
    { \serr{taint} }{Isolation error}
    {END}
  \\
  \gramdefshort{Interpreter}{Ξ}
    { \msi{m}{e} }{Expression, memory}
    { \msi{m}{i} }{Instruction, memory}
    { Ω          }{Error}
    {END}
  \end{align*}
  \end{minipage}
}}
  \caption{Memory and values}
  \label{fig:interp}
\end{figure*}%

\subsection*{Evaluation}

Operational semantics described thereafter are a binary relation between states
$Ξ$ of an interpreter described in Figure~\ref{fig:interp}.

Every syntactic constant $c$ has a corresponding value $\widehat{c}$. The same
holds for functions, because as they do not capture their lexical
environment, there is no need to build a closure.

Composite values also have their matching semantic parts: an array of values is
a value, and a structure of values is a value. The same $\widehat{\cdot}$
notation is used to remove the ambiguity.

Pointers are reduced to a memory path $φ$ that is an evaluated left-value: type
information is removed from the field names, and array indices are evaluated to
integers. Also, names are made explicit by adjoining the name of local variables
with the index of the stack frame they belong to. This is necessary in the cases
where two frames hold a variable with the same name; for example in the presence
of recursive functions.

The semantics described here are given in the style of Plotkin's Structural
Operational Semantics\cite{sos-jlap}: expressions are gradually reduced to
constants, and instructions are simplified until a terminal instruction of the
form $\iPass$ or $\iReturn{v}$.

\paragraph{Reading memory}

A variable is evaluated in two steps ; first, its address is computed.%
{ \small \[
  \semrule{Phi-Var}
\] }%
$\mathrm{Lookup} : \textsc{Mem} × \textsc{Id} → \textsc{Addr}$
is an operator mapping variable names to addresses. That is,
it performs name resolution. It returns $(n, x)$ where $n$ is the size of the
stack if a local variable of this name exists ; or then $(x)$ if a global of
this name exists.

Then, an address is a path $φ$, that is used to access the corresponding value
stored in $m$.

{\small \[
  \semrule{Exp-Lv}
\]}%

We omit here a formal definition of $m[\cdot]_Φ$. In a nutshell, it walks the
memory to return the value ultimately described by $φ$. It can raise
$\serr{array}$ if a bad array access occurs or $\serr{ptr}$ if \eNull is
dereferenced.

\paragraph{Writing memory}

The $m[\cdot]_Φ$ notation is extended to perform updates. We note $m[φ ← v]_Φ$
the memory state obtained by replacing the value at $φ$ by $v$. The same kind of
errors can occur.

{\[ \small
  \semrule{Exp-Set}
\] }%

\paragraph{Variable declaration} extends the current stack frame with a new
binding $x↦v$.%
{ \small \[ \semrule{Decl} \]}%
It relies on the following operator:%
{ \small
\begin{align*}
  \mathrm{Extend} : \textsc{Mem}×\textsc{Id}×\textsc{Val} &→ \textsc{Mem}\\
  \mathrm{Extend}(f::fs, g), x) &= (((x↦v)::f) :: fs), g) \\
\end{align*} }%
\paragraph{Function call} uses a complex rule, because it handles the calling
convention (pushing and popping parameters on the stack). We suppose that all
functions exit through a $\iReturn{\cdot}$ instruction.%
{\small \[ \semrule{Exp-Call} \] }%
$\mathrm{Push} : \textsc{Mem} × \textsc{Frame} → \textsc{Mem}$
adds a new stack frame, and
$\mathrm{Pop} : \textsc{Mem} → \textsc{Mem}$
removes it.

$\mathrm{Cleanup} : \textsc{Mem} → \textsc{Mem}$ removes references to dangling
pointers. It walk all the memory and replaces references to the current stack
frame\footnote{That is, every address of the form $(n,x)$
where $n$ is the current size of the stack.}
with $\eNull$. For example:%
{\small \begin{align*}
  \mathrm{Cleanup} &
  ([ [x ↦ 0 ] ; [ p → \{t: \&(2, x); u: 5\} ] ], [~]) \\
                   &
  ([ [x ↦ 0 ] ; [ p → \{t: \eNull; u: 5\} ] ], [~]) \\
\end{align*} }%
\paragraph{System calls} are emulated through the $\eTaint{\cdot}$ operator. For
example, the bridge between the functions \texttt{read()} and
\texttt{sys\_read()} is the following. Integer parameters don't need to be
converted, as they do not have qualifiers.

\begin{verbatim}
read = fun (fd, p, n) {
  Decl up = Taint(p) in {
    sys_read (fd, up, n)
  }
}
\end{verbatim}

Its evaluation is:%
%{\small \[ \semrule{Exp-Tainted} \]} % TODO

To allow a safe copy between userspace and the kernel, the Linux kernel provides
the macros \texttt{get\_user()} or \texttt{put\_user()}, which check and copy
scalar data, or \url{copy_from_user()} and \texttt{copy\_to\_user()} which act
similarly to \texttt{memcpy()}. All of these constructs return the error
\texttt{-EFAULT} when the user pointer is within the bounds of the kernel's
memory. To model them, we provide the $\uGet{\cdot}{\cdot}$ and
$\uPut{\cdot}{\cdot}$ operators that can copy a value at a time.%

Their semantics is not detailed, but it consists in checking that the user
pointer is of the form $\vTainted{φ}$. If it is the case, then a copy from $φ$
(in the case of $⇐_U$) or to $φ$ (in the case of $⇒_U$) is performed and the
expressions reduces to $1$. Else, no copy is done and it reduces to $0$.

\paragraph{Contexts}

To simplify the presentation of evaluation rules, we use reduction contexts, as
described by Felleisen \emph{et al.}~\cite{wright92syntactic,tcs92-fh}. The idea
is that if it is possible to reduce an expression $e_1$ to an expression $e_2$,
then it is possible to reduce a bigger expression where $e_1$ appears by
substituting it by $e_2$.

To make this work we have to proceed in three steps: split an expression
according to a context, apply a reduction under a context, and merge the reduced
expression with a context.

\begin{figure}

  {\small {

\begin{align*}
  C \gramisa & \ctxEmpty \\
     \gramor & \ctxOp{C}{e} \gramorx \ctxOp{v}{C} \gramorx \ctxUnOp{C} \\
     \gramor & \ctxSet{C}{e} \gramorx \ctxSet{φ}{C} \\
     \gramor & \{ l_1:v_1 ; … ; l_i:C ; … ; l_n:e_n \} \\
     \gramor & [ v_1 ; … ; C ; … ; e_n ] \\
     \gramor & C (e_1, …, e_n) \gramorx f (v_1, …, C, …, e_n) \\
     \gramor & \eTaint{C} \\
     \gramor & \uGet{C}{e} \gramorx \uGet{φ}{C} \\
     \gramor & \uPut{C}{e} \gramorx \uPut{v}{C} \\
     \gramor & \&~C  \\
     \gramor & \ctxLvDeref{C}
               \gramorx \ctxLvField{C}{l_S}
               \gramorx \ctxLvIndex{C}{e}
               \gramorx \ctxLvIndex{φ}{C} \\
     \gramor & C;i \\
     \gramor & \iIf{C}{i_1}{i_2} \\
     \gramor & \iReturn{C} \\
     \gramor & \iDecl{x}{C}{i}
\end{align*}}}%

\caption{Reduction contexts}
\label{fig:ctxs}

\end{figure}

Splitting across a context corresponds to defining a grammar of contexts. By
defining these (Figure~\ref{fig:ctxs}), we make an explicit choice of evaluating some constructs in a
left-to-right order. For example, the contexts for binary operations are
$C~\opbin~e$ and $v~\opbin~C$, so it is impossible to start reducing the right
part before the left one has been fully evaluated.


A similar remark can be done for $n$-ary constructs (structure and array
literals, as well as function calls): because there are always values on the
left hand of $C$, arguments are evaluated left-to-right.

The second step is expressed in the following rule. Any transition between
interpreter states can be lifted in a bigger context.%
{\small \[
    \semrule{Ctx}
\]}%
The $\ctxSub{C}{\cdot}$ operator corresponds to the last operation: it pastes an
expression in place of the unique "hole" $\ctxEmpty{}$ that appears in each
context \footnote{ In the definition of C, every alternative produces exactly
  one nonterminal $C$ or one terminal $\ctxEmpty{}$. So, every derivation tree
is linear, and $\ctxEmpty{}$ appears exactly once in every evaluation context. }
.

For example, let us unroll the evaluation of
$3+x$ to the value $\widehat{5}$
starting from a memory state $m = ([~], \{x ↦ \widehat{2}\}) $.
It is also depicted in Figure~\ref{fig:eval-steps}.

\begin{enumerate}[(a)]
\item % (a)
  Let us first remark that $\mm{m}{3}{m}{\widehat{3}}$
  (because of \textsc{Exp-Cst})
\item % (b)
  By applying \textsc{Ctx} from (a)
  with $C = \ctxEmpty{} + x$, we obtain
  $\mm{m}{3+x}{m}{\widehat{3}+x}$.
  Note that with such an evaluation context, the right hand operand does not
  have to be evaluated.
\item % (c)
  $x$, as a variable name, is a left-value. To evaluate it, the first step is to
  turn it into a path $φ = \mathrm{Lookup}(x, m)$ (because of rule
  \textsc{Phi-Var}). Because there are no local variables and a global variable
  named $x$, $φ = (x)$. Note that in this step, no memory lookup was involved
  (only the names of variables were used). So $\mm{m}{x}{m}{(x)}$.
\item % (d)
  In order to evaluate this path into a value, we have to perform a memory
  lookup. The global variable $(x)$ maps to $2$ in $m$, so according to
  \textsc{Exp-Lv}, $\mm{m}{(x)}{m}{\widehat{2}}$.
\item % (e)
  Because of closure of $→$, we get from (c) and (d) that
  $\mm{m}{x}{m}{\widehat{2}}$.
\item % (f)
  By applying \textsc{Ctx} with $C = \widehat{3} + \ctxEmpty{}$ to (e),
  $\mm{m}{\widehat{3} + x}{m}{\widehat{3} + \widehat{2}}$ holds.
  The fact that the left hand operand is a value is important.
\item % (g)
  Because of \textsc{Exp-BinOp},
  $\mm{m}{
  \widehat{3} + \widehat{2}
  }{m}{
  \widehat{3} \widehat{+} \widehat{2}
  }$, ie
  $\mm{m}{
  \widehat{3} + \widehat{2}
  }{m}{
  \widehat{5}
  }$.
\item % (h)
  By closure of $→$, we get from
  (b), (f) and (g) that
  $\mm{m}{3+x}{m}{\widehat{5}}$
  .
\end{enumerate}

\begin{figure}
  \small

\begin{mathpar}

  \inferrule*[left=({\normalfont b})]{
    \inferrule*[left=({\normalfont a})]{ }{\mms{3}{\widehat{3}}}
  }{
    \mms{3+x}{\widehat{3}+x}
  }

  \inferrule*[left=({\normalfont f})]{
    \inferrule*[left=({\normalfont e})]{
      \inferrule*[left=({\normalfont c})]{ }{ \mms{x}{(x)} }
      \\
      \inferrule*[left=({\normalfont d})]{ }{ \mms{(x)}{\widehat{2}} }
    }{
      \mms{x}{\widehat{2}}
    }
  }{
    \mms{\widehat{3}+x}{\widehat{3}+\widehat{2}}
  }

  \inferrule*[left=({\normalfont h})]
    {
      (b)
      \\
      (f)
      \\
  \inferrule*[left=({\normalfont g})]
    { }
    {
      \mms{\widehat{3}+\widehat{2}}{\widehat{3}\widehat{+}\widehat{2}}
    }
    }
    {
      \mms{3+x}{\widehat{5}}
    }
\end{mathpar}

\caption{Evaluation of $3+x$ into $\widehat{5}$}
\label{fig:eval-steps}

\end{figure}

Evaluation rules are given in annex in Figures~\ref{fig:eval-exp}
and~\ref{fig:rules}. Most are simple, but a few deserve to be explained in
detail.

\paragraph{Error propagation} is done in two cases. First, if an expression
produces an error (seen as a value), then the same error (seen as a state $Ξ$)
propagates to the interpreter. Second, if a sub-expression causes an error, then
a bigger expression causes the same error.%
{ \small
\begin{mathpar}
    \semrule{Exp-Err}

    \semrule{Eval-Err}
\end{mathpar}}%

\paragraph{Programs} are evaluated one sentence after another. Declarations add
a global variable.

\begin{mathpar}
    \semrule{T-Exp}

    \semrule{T-Var}
\end{mathpar}

\section{Typage}

\begin{itemize}
\item ordre des sections
\item versions $Γ ⊢ i$ des propriétés
\item preuve de progres : état mémoire : doublet/triplet
\item définir les opérations d'ajout/remplacement sur les contextes de typage
\item 2 pointeurs peuvent etre égaux sans comparer les valeurs pointées
\item extension de contextes : :: ou , ?
\end{itemize}

\subsection*{Fonctions}

\begin{itemize}
\item
  page 50 règle CALL une remarque disant que cette règle doit être
  utilisée avec une autre qui va typer le corps de la fonction (mettre
  la ref) parce que sinon ça surprend
\item
  5.5 le fait de choisir une unique variable R t'oblige à ajouter une
  opération de suppression du R de la fonction appelante factice.
  Pourquoi ne pas générer des variables fraîches à partir du nom de la
  fonction + un identifiant unique ?
\item
  lemme 5.1 cas fonction, à quoi ça sert d'introduire la notation t'
  alors qu'il n'apparaît pas dans une règle ?
\end{itemize}

\subsection*{Rq}
(passe Sarah 17/01)

\begin{itemize}
\item
  5.3 left-values la règle LV-VAR suppose que x n'apparaît qu'une fois
  dans $\Gamma$ ou alors toujours accompagné du même type
\item
  p53 le terme de dérivation (première phrase de la preuve) n'a jamais
  été expliqué ?
\item
  lemme 5.1 constantes. Il faut expliquer à quel ensemble n et f
  appartiennent
\item
  lemme 5.2 même remarque que 5.1 concernant n et f (plus confusion f
  float et f fonction)
\item
  lemme 5.3 ça ne marche que si une variable n'apparaît qu'une fois dans
  le contexte ou avec toujours le même type (cf rem ci-dessous sur 5.3)
\item
  il manque les preuves de 5.3 et 5.4
\item
  lemme 5.4 $dom(\Gamma)$ a été défini quelque part ?
\item
  théormèe 5.2 rappeler où a été défini l'évaluation d'une expression et
  dans quel cas elle produit des valeurs
\end{itemize}

\section{Qualificateurs}

\begin{itemize}
\item appliquer taint sur des sous-valeurs?
\item vTaint doit se propager aux accès de champ
\item étendre l'état mémoire aux variables utilisateur
\end{itemize}

(passe Sarah)

\begin{itemize}
\item
  6.1.1 français dans ``qui représente qui contrôle sa valeur''
\item
  6.1.1 mettre une ref sur la description du noyau linux
\item
  la traduction de taintage par teintage est incorrecte (et des fois du
  garde la même orthographe que celle anglaise avec le `a') La
  traduction de tainted c'est plutôt sali, pollué. Tu peux aussi garder
  le terme anglais et le mettre en italique
\item
  j'ai arrêté de lire à partir de 6.2 parce que le texte n'est pas
  vraiment clair
\end{itemize}

% TODO le cimetière des règles

%\begin{mathpar}
%\irule{Taint-Erase}
  %{ }
  %{ \mmi{m}{\iTaint{x}}{m}{\iPass} }
%\end{mathpar}

%\begin{mathpar}
%\irule{Taint-Write-Old}
  %{ }
  %{ \mmi{m}{\iTaint{x}}{m[x ← \vTainted{m[x]}]}{\iPass} }
%\end{mathpar}

%\begin{mathpar}
%\irule{Taint-Write}
  %{ }
  %{ \mmi{m}{\iTaint{φ}}{m[φ ← \vTainted{m[φ]}]}{\iPass} }
%\end{mathpar}

\section*{Extrait PLAS}

The main distinctiveness is that instead of having a plain pointer type
$t~*$, our one is decorated with a type qualifier $q$. This annotation expresses
who controls the value of the pointer. If the kernel controls the value of the
pointer, then it cannot be abused. On the other hand, one has to be careful
with user-controlled pointers, because the caller can abuse the kernel and
access reserved memory. The only safe case when dereferencing such a pointer is
if its value is outside the kernel's memory.

In order to avoid dangerous cases, we have to dynamically check that the
destination of every user-controlled pointer is in userspace. Kernel pointers
(that is to say, kernel-controlled pointers) can be dereferenced without further
check, but user pointers have to be manipulated with a restricted interface that
will check whether their destination is in userspace.

As mentioned before, this is done using the following constructs:%
{\small
\begin{mathpar}
    \disprule{GetU}

    \disprule{PutU}
\end{mathpar}}%
To add qualifiers to a type system, the rules of interest are those that
manipulate pointers: dereferencing, pointer arithmetic and referencing (taking
the address of a left-value).

Dereferencing the easiest one ; our goal is to authorize dereferencing only
\qKernel pointers:

{\small \[ \disprule{Lv-Deref} \]}%

Pointer arithmetic can be done inside a \qUser or \qKernel memory zone. There is
no concern of jumping from userspace to kernelspace, because pointer arithmetic
is checked at runtime: if these operators overflow or are applied to a bad
pointer (such as a pointer to an integer field), $\serr{ptr}$ is raised.

{\small \[ \disprule{Ptr-Arith} \]}%

The reference case is trickier because a type qualifier has to be synthesized.
Because it is created on the kernel stack, it has a \qKernel qualifier in all
cases:
{\small \[
  \disprule{Addr}
\]}%

The $\eTaint{\cdot}$ operator turns a \qUser pointer into a \qKernel pointer.
It is an important rule, because it is the only source of \qUser pointers in the
type system.
%{\small \[ \disprule{Taint} \] }% TODO
The return value of a function is emulated with a virtual left-value $\vRet$.%
{\small \begin{mathpar}
  \disprule{Return}

  \disprule{Fun}
\end{mathpar}}%

\section{Implem}

The language described above, as well as a type inference algorithm, have been
implemented in OCaml as part of the Newspeak framework of program
analysis\cite{newspeak}. It is released under the GNU Lesser General Public
License, and is available on \texttt{http://penjili.org} (directory
\texttt{src/ptrtype} in the distribution). Our implementation consists of the
following steps.

but to analyze larger parts of the kernel, it may be
necessary to define a ``maximal'' configuration file (which is impossible
because of incompatibilities between some options).

\section{Étude de cas}

Le paramètre \texttt{data} provient de l'espace utilisateur via un appel
système. Un appelant malveillant peut se servir de cette fonction pour lire la
mémoire du noyau à travers le message d'erreur.

Le problème est modélisé de la façon suivante : on associe à chaque variable
\texttt{x} un type de données \texttt{t}, ce que l'on note \texttt{x:t}. En
plus des types présents dans le langage C, on ajoute une distinction
supplémentaire pour les pointeurs. D'une part, les pointeurs ``noyau'' (de type
\texttt{t~*}) sont créés en prenant l'adresse d'un objet présent dans le code
source. D'autre part, les pointeurs ``utilisateurs'' (leur type est noté
\texttt{t user*}) proviennent des interfaces avec l'espace utilisateur.

Il est sûr de déréférencer un pointeur noyau, mais pas un pointeur
utilisateur. L'opérateur \texttt{*} prend donc un \texttt{t *} en entrée
et produit un \texttt{t}.

Pour faire la vérification de type sur le code du programme, on a besoin de
quelques règles. Tout d'abord, les types suivent le flot de données.
C'est-à-dire que si on trouve dans le code \texttt{a = b}, \texttt{a} et
\texttt{b} doivent avoir un type compatible. Ensuite, le qualificateur
\texttt{user} est récursif : si on a un pointeur utilisateur sur une structure,
tous les champs pointeurs de la structure sont également utilisateur. Enfin, le
déréférencement s'applique aux pointeurs noyau seulement : si le code contient
l'expression \texttt{*x}, alors il existe un type \texttt{t} tel que
\texttt{x:t*} et \texttt{*x:t}.

Appliquons ces règles à l'exemple de la figure \ref{fig:radeon-bug} : on suppose
que l'interface avec l'espace utilisateur a été correctement annotée. Cela
permet de déduire que \texttt{data:void user*}. En appliquant la première règle
à la ligne 6, on en déduit que \texttt{info:struct drm\_radeon\_info user*}
(comme en C, on peut toujours convertir de et vers un pointeur sur
\texttt{void}).

Pour déduire le type de \texttt{value\_ptr} dans la ligne 7, c'est la
deuxième règle qu'il faut appliquer : le champ \texttt{value} de
la structure est de type \texttt{uint32\_t~*} mais on y accède à travers
un pointeur utilisateur, donc \texttt{value\_ptr:uint32\_t user*}.

% TODO faux

À la ligne 8, on peut appliquer la troisième règle : à cause du déréférencement,
on en déduit que \texttt{value\_ptr:t *}, ce qui est une contradiction puisque
d'après les lignes précédentes, \texttt{value\_ptr:uint32\_t user*}.

Si la ligne 3 était remplacée par l'appel à \texttt{copy\_from\_user}, il n'y
aurait pas d'erreur de typage car cette fonction peut accepter les arguments
\texttt{(uint32\_t~*, uint32\_t user*, size\_t)}.

Le principe de cette technique (associer des types aux valeurs puis restreindre
les opérations sur certains types) peut être repris. Par exemple, si on définit
un type ``numéro de bloc'' comme étant un nouvel alias de \texttt{int}, on peut
considérer que multiplier deux telles valeurs est une erreur.

\section{Conclusion}

\subsection{Future work}

We showed that type theory can be a useful tool for verifying the absence of
certain run-time properties. While adding static labels to variables seems to be
a crude approximation of reality, in some cases it has enough power to capture
real-world problems.

In this particular example, we work around C's lack of abstract types in order
to disallow dereference for a certain class of pointers, distinguished by
syntactic rules.

We defined an imperative language with an explicit stack, and described
operational semantics for it modelling that of the C programming language. It
includes a memory model that expresses the separation between user and kernel
spaces present in most operating systems. We added a type system that is sound
with respect to a property of isolation between this two memory spaces.

Finally, we demonstrate an implementation on this analysis on a bug that
affected the Linux kernel.

A first step towards making this analysis more practical is to demonstrate its
scalability by running it on larger fragments of the kernel.

There are also several places where we can improve significantly the
expressivity of our type system. For example, our current type system is only
monomorphic; but it would make sense to generalize free qualifier variables in
the type of global functions.
